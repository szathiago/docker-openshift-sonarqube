(window.webpackJsonp=window.webpackJsonp||[]).push([[282,266,368],{1098:function(e,n,t){(e.exports=t(540)(!1)).push([e.i,'.documentation-page-header{margin:10px 20px}.documentation-footer .page-footer-menu,.documentation-footer div{max-width:740px}.documentation-content{padding:32px 64px}.documentation-content.markdown{font-size:16px;line-height:1.7}.documentation-content.markdown>h1{font-size:24px;padding-top:8px;margin-bottom:2em}.documentation-content.markdown h2{font-weight:800;margin-top:3em}.documentation-content.markdown h3{font-size:16px;margin-bottom:.8em}.documentation-content.markdown pre{border:1px solid #e6e6e6;border-radius:3px;background-color:rgba(0,0,0,.06)}.documentation-content.markdown .alert,.documentation-content.markdown p,.documentation-content.markdown pre,.documentation-content.markdown table{margin:.8em 0 2em}.documentation-content.markdown ul{margin:0 0 2em}.documentation-content.markdown ul>ul{margin:0}.documentation-content.markdown p+ol,.documentation-content.markdown p+pre,.documentation-content.markdown p+ul{margin:-1em 0 2em}.documentation-content.markdown li>p,.documentation-content.markdown li>p+ol,.documentation-content.markdown li>p+ul{margin:0}.documentation-content.markdown img[src$=".svg"]{vertical-align:text-bottom}.documentation-content.markdown .alert p{margin:0}.documentation-content.markdown .collapse-container{border:1px solid #e6e6e6;border-radius:2px;background-color:#f3f3f3;padding:8px;margin:.8em 0 2em}.documentation-content.markdown .collapse-container>a:first-child{display:block}.documentation-content.markdown .collapse-container>a:first-child:focus{color:#236a97}.documentation-content.markdown .collapse-container :last-child{margin-bottom:0}',""])},1099:function(e,n,t){var o=t(1098);"string"==typeof o&&(o=[[e.i,o,""]]);var a={hmr:!0,transform:void 0,insertInto:void 0};t(539)(o,a);o.locals&&(e.exports=o.locals)},1153:function(e,n,t){"use strict";e.exports=[{path:"analysis/background-tasks",content:'---\ntitle: Background Tasks\n---\n\nA Background Task can be:\n* the import of an Analysis Report\n* the computation of a Portfolio\n* the import or export of a project\n\n## What happens after the scanner is done analyzing?\n\nAnalysis is not complete until the relevant Background Task has been completed. Even though the SonarQube Scanner\'s log shows `EXECUTION SUCCESS`, the analysis results will not be visible in the SonarQube project until the Background Task has been completed. After a SonarQube Scanner has finished analyzing your code, the result of the analysis (Sources, Issues, Metrics) -  the Analysis Report - is sent to SonarQube Server for final processing by the Compute Engine. Analysis Reports are queued and processed serially.\n\nAt the Project level, when there is a pending Analysis Report waiting to be consumed, you have a "Pending" notification in the header, next to the date of the most recent completed analysis.\n\nGlobal Administrators can view the current queue at **[Administration > Projects > Background Tasks](/#sonarqube-admin#/admin/background_tasks)**. Project administrators can see the tasks for a project at **Administration > Background Tasks**.\n\n## How do I know when analysis report processing fails?\nBackground tasks usually succeed, but sometimes unusual circumstances cause processing to fail. Examples include:\n\n* running out of memory while processing a report from a very large project\n* hitting a clash between the key of an existing module or project and one in the report\n* ...\n\nWhen that happens, the failed status is reflected on the project homepage, but that requires someone to notice it. You can also choose to be notified by email when background tasks fail - either on a project by project basis, or globally on all projects where you have administration rights, in the **Notifications** section of your profile.\n\n## How do I diagnose a failing background task?\nFor each Analysis Report there is a dropdown menu allowing you to access to the "Scanner Context" showing you the configuration of the Scanner at the moment when the code scan has been run.\n\nIf processing failed for the task, an additional option will be available: "Show Error Details", to get the technical details why the processing of the Background Task failed.\n\n## How do I cancel a pending analysis report?\nAdministrators can cancel the processing of a pending task by clicking:\n\n* on the red \'x\' available on each line of a `Pending` task\n* on the red "bulk cancel" option next to the pending jobs count. This button cancels all pending tasks.\n\nOnce processing has begun on a report, it\'s too late to cancel it.\n\n'},{path:"analysis/generic_issue",content:'---\ntitle: Generic Issue Data\n---\n\nSonarQube supports a generic import format for raising "external" issues in code. It is intended to allow you to import the issues from your favorite linter even if no plugin exists for it.\n\nExternal issues suffer from two important limitations:\n\n* they cannot be managed within SonarQube; for instance, there is no ability to mark them False Positive.\n* the activation of the rules that raise these issues cannot be managed within SonarQube. In fact, external rules are not visible in the Rules page or reflected in any Quality Profile.\n\nExternal issues and the rules that raise them must be managed in the configuration of your linter. \n\n## Import\nThe analysis parameter `sonar.externalIssuesReportPaths` accepts a comma-delimited list of paths to reports.\n\nEach report must contain, at top-level, an array of `Issue` objects named `issues`.\n\n#### Issue fields:\n\n* `engineId` - string\n* `ruleId` - string\n* `primaryLocation` - Location object \n* `type` - string. One of BUG, VULNERABILITY, CODE_SMELL\n* `severity` - string. One of BLOCKER, CRITICAL, MAJOR, MINOR, INFO\n* `effortMinutes` - integer, optional. Defaults to 0\n* `secondaryLocations` - array of Location objects, optional\n\n#### Location fields:\n\n* `message` - string\n* `filePath` - string\n* `textRange` - TextRange object, optional for secondary locations only\n\n#### TextRange fields:\n\n* `startLine` - integer. 1-indexed\n* `endLine` - integer, optional. 1-indexed\n* `startColumn` - integer, optional. 0-indexed\n* `endColumn` - integer, optional. 0-indexed\n\nHere is an example of the expected format:\n\n\t{ "issues": [\n\t\t{\n\t\t  "engineId": "test",\n\t\t  "ruleId": "rule1",\n\t\t  "severity":"BLOCKER",\n\t\t  "type":"CODE_SMELL",\n\t\t  "primaryLocation": {\n\t\t\t"message": "fully-fleshed issue",\n\t\t\t"filePath": "sources/A.java",\n\t\t\t"textRange": {\n\t\t\t  "startLine": 30,\n\t\t\t  "endLine": 30,\n\t\t\t  "startColumn": 9,\n\t\t\t  "endColumn": 14\n\t\t\t}\n\t\t  },\n\t\t  "effortMinutes": 90,\n\t\t  "secondaryLocations": [\n\t\t\t{\n\t\t\t  "message": "cross-file 2ndary location",\n\t\t\t  "filePath": "sources/B.java",\n\t\t\t  "textRange": {\n\t\t\t\t"startLine": 10,\n\t\t\t\t"endLine": 10,\n\t\t\t\t"startColumn": 6,\n\t\t\t\t"endColumn": 38\n\t\t\t  }\n\t\t\t}\n\t\t  ]\n\t\t},\n\t\t{\n\t\t  "engineId": "test",\n\t\t  "ruleId": "rule2",\n\t\t  "severity": "INFO",\n\t\t  "type": "BUG",\n\t\t  "primaryLocation": {\n\t\t\t"message": "minimal issue raised at file level",\n\t\t\t"filePath": "sources/Measure.java"\n\t\t  }\n\t\t}\n\t]}\n'},{path:"analysis/generic_test",content:'---\ntitle: Generic Test Data\n---\n\nOut of the box, SonarQube supports generic formats for test coverage and test execution import. If your coverage engines\' native output formats aren\'t supported by your language plugins, simply covert them to these formats.\n\n## Generic Coverage\nReport paths should be passed in a comma-delimited list to:\n\n * `sonar.coverageReportPaths`\n\nThe supported format is described by the `sonar-generic-coverage.xsd`:\n\n\t<xs:schema>\n\t  <xs:element name="coverage">\n\t\t<xs:complexType>\n\t\t  <xs:sequence>\n\t\t\t<xs:element name="file" minOccurs="0" maxOccurs="unbounded">\n\t\t\t  <xs:complexType>\n\t\t\t\t<xs:sequence>\n\t\t\t\t  <xs:element name="lineToCover" minOccurs="0" maxOccurs="unbounded">\n\t\t\t\t\t<xs:complexType>\n\t\t\t\t\t  <xs:attribute name="lineNumber" type="xs:positiveInteger" use="required"/>\n\t\t\t\t\t  <xs:attribute name="covered" type="xs:boolean" use="required"/>\n\t\t\t\t\t  <xs:attribute name="branchesToCover" type="xs:nonNegativeInteger"/>\n\t\t\t\t\t  <xs:attribute name="coveredBranches" type="xs:nonNegativeInteger"/>\n\t\t\t\t\t</xs:complexType>\n\t\t\t\t  </xs:element>\n\t\t\t\t</xs:sequence>\n\t\t\t  <xs:attribute name="path" type="xs:string" use="required"/>\n\t\t\t  </xs:complexType>\n\t\t\t</xs:element>\n\t\t  </xs:sequence>\n\t\t  <xs:attribute name="version" type="xs:positiveInteger" use="required"/>\n\t\t</xs:complexType>\n\t  </xs:element>\n\t</xs:schema>\n\nand looks like this:\n\n\t<coverage version="1">\n\t  <file path="xources/hello/NoConditions.xoo">\n\t\t<lineToCover lineNumber="6" covered="true"/>\n\t\t<lineToCover lineNumber="7" covered="false"/>\n\t  </file>\n\t  <file path="xources/hello/WithConditions.xoo">\n\t\t<lineToCover lineNumber="3" covered="true" branchesToCover="2" coveredBranches="1"/>\n\t  </file>\n\t</coverage>\n\nThe root node should be named `coverage`. Its version attribute should be set to `1`.\n\nInsert a `file` element for each file which can be covered by tests. Its `path` attribute can be either absolute or relative to the root of the module.\nInside a `file` element, insert a `lineToCover` for each line which can be covered by unit tests. It can have the following attributes:\n* `lineNumber` (mandatory)\n* `covered` (mandatory): boolean value indicating whether tests actually hit that line\n* `branchesToCover` (optional): number of branches which can be covered\n* `coveredBranches` (optional): number of branches which are actually covered by tests\n\n## Generic Execution\nReport paths should be passed in a comma-delimited list to:\n\n* `sonar.testExecutionReportPaths`\n\nThe supported format looks like this:\n\n\t<testExecutions version="1">\n\t  <file path="testx/ClassOneTest.xoo">\n\t\t<testCase name="test1" duration="5"/>\n\t\t<testCase name="test2" duration="500">\n\t\t  <skipped message="short message">other</skipped>\n\t\t</testCase>\n\t\t<testCase name="test3" duration="100">\n\t\t  <failure message="short">stacktrace</failure>\n\t\t</testCase>\n\t\t<testCase name="test4" duration="500">\n\t\t  <error message="short">stacktrace</error>\n\t\t</testCase>\n\t  </file>\n\t</testExecutions>\n\t\nThe root node should be named `testExecutions`. Its version attribute should be set to `1`.\n\nInsert a `file` element for each test file. Its `path` attribute can be either absolute or relative to the root of the module.\n\n**Note** unlike for coverage reports, the files present in the report must be test file names, not source code files covered by tests.\n\nInside a `file` element, insert a `testCase` for each test run by unit tests. It can have the following attributes/children:\n\n* `testCase` (mandatory)\n  * `name` (mandatory): name of the test case\n  * `duration` (mandatory): long value in milliseconds\n \n  * `failure|error|skipped` (optional): if the test is not OK, report the cause with a message and a long description\n    * `message` (mandatory): short message describing the cause\n    * `stacktrace` (optional): long message containing details about `failure|error|skipped` status\n'},{path:"analysis/index",content:"---\ntitle: Analyzing Source Code\n---\n\nOnce the SonarQube platform has been installed, you're ready to install an analyzer and begin creating projects. To do that, you must install and configure the scanner that is most appropriate for your needs. Do you build with:\n\n\x3c!-- sonarcloud --\x3e\n* TravisCI for SonarCloud - [SonarCloud Travis addon](https://docs.travis-ci.com/user/sonarcloud/)\n\x3c!-- /sonarcloud --\x3e\n* Gradle - [SonarQube Scanner for Gradle](https://redirect.sonarsource.com/doc/gradle.html)\n* MSBuild - [SonarQube Scanner for MSBuild](https://redirect.sonarsource.com/doc/install-configure-scanner-msbuild.html)\n* Maven - use the [SonarQube Scanner for Maven](https://redirect.sonarsource.com/doc/install-configure-scanner-maven.html)\n* Jenkins - [SonarQube Scanner for Jenkins](https://redirect.sonarsource.com/plugins/jenkins.html)\n* VSTS / TFS - [SonarQube Extension for VSTS-TFS](https://redirect.sonarsource.com/doc/install-configure-scanner-tfs-ts.html)\n* Ant - [SonarQube Scanner for Ant](https://redirect.sonarsource.com/doc/install-configure-scanner-ant.html)\n* anything else (CLI) - [SonarQube Scanner](https://redirect.sonarsource.com/doc/install-configure-scanner.html)\n\n**Note** that we do not recommend running an antivirus scanner on the machine where a SonarQube analysis runs, it could result in unpredictable behavior.\n\n\nA project is created in the platform automatically on its first analysis. However, if you need to set some configuration on your project before its first analysis, you have the option of provisioning it via Administration options.\n\n## What does analysis produce? \nSonarQube can perform analysis on 20+ different languages. The outcome of this analysis will be quality measures and issues (instances where coding rules were broken). However, what gets analyzed will vary depending on the language:\n\n* On all languages, \"blame\" data will automatically be imported from supported SCM providers. Git and SVN are supported automatically. Other providers require additional plugins.\n* On all languages, a static analysis of source code is performed (Java files, COBOL programs, etc.)\n* A static analysis of compiled code can be performed for certain languages (.class files in Java, .dll files in C#, etc.)\n* A dynamic analysis of code can be performed on certain languages.\n\n## Will _all_ files be analyzed?\nBy default, only files that are recognized by a language analyzer are loaded into the project during analysis. For example if your SonarQube instance had only SonarJava SonarJS on board, all .java and .js files would be loaded, but .xml files would be ignored. \n\n## What happens during analysis?\nDuring analysis, data is requested from the server, the files provided to the analysis are analyzed, and the resulting data is sent back to the server at the end in the form of a report, which is then analyzed asynchronously server-side.\n\nAnalysis reports are queued, and processed sequentially, so it is quite possible that for a brief period after your analysis log shows completion, the updated values are not visible in your SonarQube project. However, you will be able to tell what's going on because an icon will be added on the project homepage to the right of the project name. Mouse over it for more detail (and links if you're logged in with the proper permissions).\n\n![background task processing in progress.](/images/backgroundTaskProcessingInProgress.jpeg)\n\n\nThe icon goes away once processing is complete, but if analysis report processing fails for some reason, the icon changes:\n\n![background task processing failed.](/images/backgroundTaskProcessingFailedIcon.jpeg)\n\n\n## F.A.Q.\n\n**Q.** Analysis errors out with `java.lang.OutOfMemoryError: GC overhead limit exceeded`. What do I do?  \n**A.** This means your project is too large or too intricate for the scanner to analyze with the default memory allocation. To fix this you'll want to allocate a larger heap (using `-Xmx[numeric value here]`) to the process running the analysis. Some CI engines may give you an input to specify the necessary values, for instance if you're using a Maven Build Step in a Jenkins job to run analysis. Otherwise, use Java Options to set a higher value. Note that details of setting Java Options are omitted here because they vary depending on the environment.\n"},{path:"analysis/pull-request",content:'---\ntitle: Pull Request Analysis\n---\n\n\x3c!-- sonarqube --\x3e\n\n_Pull Request analysis is available as part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)_\n\n\x3c!-- /sonarqube --\x3e\n\n\nPull Request analysis allows you to:\n\n* see your Pull Request (PR) analysis results in the SonarQube UI and see the green or red status to highlight the existence of open issues.\n* automatically decorate your PRs with SonarQube issues in your SCM provider\'s interface. \n\nPRs are visible in SonarQube from the "branches and pull requests" dropdown menu of your project.\n\nWhen PR decoration is enabled, SonarQube publishes the status of the analysis (Quality Gate) on the PR.\n\nWhen "Confirm", "Resolved as False Positive" or "Won\'t Fix" actions are performed on issues in SonarQube UI, the status of the PR is updated accordingly. This means, if you want to get a green status on the PR, you can either fix the issues for real or "Confirm", "Resolved as False Positive" or "Won\'t Fix" any remaining issues available on the PR.\n\nPR analyses on SonarQube are deleted automatically after 30 days with no analysis. This can be updated in **Configuration > General > Number of days before purging inactive short living branches**. \n\n\x3c!-- sonarcloud --\x3e\n## Integrations for GitHub, Bitbucket Cloud and VSTS\nIf your repositories are hosted on GitHub, Bitbucket Cloud or VSTS, check out first the dedicated ["Integrations" pages](/integrations/index). Chances are that you do not need to read this page further since those integrations handle the configuration and analysis parameters for you.\n\x3c!-- /sonarcloud --\x3e\n\n## Analysis Parameters\n### Pull Request Analysis in SonarQube\nThese parameters enable PR analysis:\n\n| Parameter Name        | Description |\n| --------------------- | ------------------ |\n| `sonar.pullrequest.branch` | The name of your PR<br/> Ex: `sonar.pullrequest.branch=feature/my-new-feature`|\n| `sonar.pullrequest.key` | Unique identifier of your PR. Must correspond to the key of the PR in GitHub or TFS. <br/> E.G.: `sonar.pullrequest.key=5` |\n| `sonar.pullrequest.base` | The long-lived branch into which the PR will be merged. <br/> Default: master <br/> E.G.: `sonar.pullrequest.base=master`|\n\n### Pull Request Decoration\nTo activate PR decoration, you need to:\n\n* declare an Authentication Token\n* specify the Git provider\n* feed some specific parameters (GitHub only)\n\n#### Authentication Token\nThe first thing to configure is the authentication token that will be used by SonarQube to decorate the PRs. This can be configured in **Administration > Pull Requests**. The field to configure depends on the provider.\n\nFor GitHub Enterprise or GitHub.com, you need to configure the **Authentication token** field. For VSTS/TFS, it\'s the **Personal access token**.\n\n#### Pull Request Provider\n| Parameter Name        | Description |\n| --------------------- | ------------------ |\n| `sonar.pullrequest.provider` | `github` or `vsts`<br/> This is the name of the system managing your PR. In VSTS/TFS, when the Analyzing with SonarQube Extension for VSTS-TFS is used, `sonar.pullrequest.provider` is automatically populated with "vsts". |\n\n#### GitHub Parameters\n| Parameter Name        | Description |\n| --------------------- | ------------------ |\n| `sonar.pullrequest.github.repository` | SLUG of the GitHub Repo |\n| `sonar.pullrequest.github.endpoint` | The API url for your GitHub instance.<br/> Ex.: `https://api.github.com/` or `https://github.company.com/api/v3/` |\n\nNote: if you were relying on the GitHub Plugin, its properties are no longer required and they must be removed from your configuration: `sonar.analysis.mode`, `sonar.github.repository`, `sonar.github.pullRequest`, `sonar.github.oauth`.\n'},{path:"analysis/scm_integration",content:"---\ntitle: SCM Integration\n---\n\nCollecting SCM data during code analysis can unlock a number of SonarQube features:\n\n* Automatic Issue Assignment\n* code annotation (blame data) in the Code Viewer\n* SCM-driven detection of new code (to help with Fixing the Water Leak). Without SCM data, SonarQube determines new code using analysis dates (to timestamp modification of lines).\n\n### Turning it on/off\nSCM integration requires support for your individual SCM provider. Git and SVN are supported by default. \x3c!-- sonarqube --\x3eFor other SCM providers, see the Marketplace.\x3c!-- /sonarqube --\x3e\n\nIf need be, you can toggle it off at global/project level via administration settings.\n\n"},{path:"analyze-a-project",content:"---\ntitle: Analyze a Project\nscope: sonarcloud\n---\n\n## Prepare your organization\n\nA project must belong to an [organization](/organizations/index). Create one if you intend to collaborate with your team mates, or use your personal organization for test purposes.\n\n[[info]]\n| ** Important note for private code:** Newly created organizations and personal organizations are under a free plan by default. This means projects analyzed on these organizations are public by default: the code will be browsable by anyone. If you want private projects, you should [upgrade your organization to a paid plan](/sonarcloud-pricing) in the \"Administration > Billing\" page of your organization.\n\nFind the key of your organization, you will need it at later stages. It can be found on the top right corner of your organization's header.\n\n## Run analysis\n\nSonarCloud currently does not trigger analyses automatically - this feature will come in a near future. Currently, it's up to you to launch them inside your\nexisting CI scripts.\n\nDepending on which cloud solution you are using for your developments, you can rely on dedicated integrations to help you:\n\n* VSTS: [read our dedicated documentation](/integrations/vsts)\n* Bitbucket Cloud: [read our dedicated documentation](/integrations/bitbucketcloud)\n* GitHub: [read our dedicated documentation](/integrations/github)\n\nIf you are not using those solutions, you will have to find out what command to execute to run the analysis. Our [tutorial](/#sonarcloud#/onboarding) will help you on this.\n"},{path:"branches/branches-faq",content:'---\ntitle: Frequently Asked Branches Questions\norder: 99\n---\n\n\x3c!-- sonarqube --\x3e\n\n_Branch analysis is available as part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)_\n\n\x3c!-- /sonarqube --\x3e\n\n\n**Q:** How long are branches retained?  \n**A:** Long-lived branches are retained until you delete them manually (**Administration > Branches**).\nShort-lived branches are deleted automatically after 30 days with no analysis.\nThis can be updated in **Configuration > General > Number of days before purging inactive short living branches**.\n\n**Q:** Do I need to have my project stored in an SCM such as Git or SVN to use this feature?  \n**A:** No, you don\'t need to be connected to a SCM. But if you use Git or SVN we can better track the new files on short-lived branches and so better report new issues on the files that really changed during the life of the short-lived branch.\n\n**Q:** If I flag an Issue as "Won\'t Fix" or "False-Positive", will it be replicated as such when merging my short-lived branch into the Master?  \n**A:** Yes. Each time there is an analysis of a long-lived branch, we look at the issues on the short-lived branches and try to synchronize them with the newly raised issues on the long-lived branch. In case you made some changes on the issues (false-positive, won\'t fix), these changes will be reported on the long-lived branch.\n\n**Q:** Can I still use `sonar.branch`?  \n**A:** `sonar.branch` is deprecated. You can still use it but it will behave the same way it always has: a separate project will be created. We encourage you to smoothly migrate your users to the new parameter `sonar.branch.name`.\nPlease note you cannot use `sonar.branch` together with `sonar.branch.name`.\n\n**Q:** Can I manually delete a branch?  \n**A:** This can be achieved by going into the Administration menu at Project\'s level, then Branches.\n\n**Q:** How do I control the lifespan of a short-lived branch?  \n**A:** As a global admin, you can set the parameter sonar.dbcleaner.daysBeforeDeletingInactiveShortLivingBranches to control how many days you want to keep an inactive short-lived branch.\n\n**Q:** Does the payload of the Webhook contain extra information related to Branches?  \n**A:** Yes, an extra node called "branch" is added to the payload.\n\n**Q:** When are Webhooks called?  \n**A:** When the computation of the background task is done for a given branch but also when an issue is updated on a short-lived branch.\n\n**Q:** What is the impact on my LOCs consumption vs my license?  \n**A:** The LOC of your largest branch are counted toward your license limit. All other branches are ignored.  \n'},{path:"branches/index",content:'---\ntitle: Branches\n---\n\n\x3c!-- sonarqube --\x3e\n_Branch analysis is available as part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)_\n\x3c!-- /sonarqube --\x3e\n\n## Table of Contents\n\n\nBranch analysis allows you to\n\n* analyze long-lived branches\n* analyze short-lived branches\n* notify external systems when the status of a short-lived branch is impacted\n\n## Branch Types\n\n### Short-lived\n\nShort-Lived\nThis corresponds to Pull/Merge Requests or Feature Branches. This kind of branch:\n\n* will disappear quickly\n* will be merged rapidly to prevent integration issues\n* is developed for a given version, so the version does not change,\n  and there is no Leak Period concept as such; it\'s all leak period\n  tracks all the new issues related to the code that changed on it.\n\n![conceptual illustration of short-lived branches.](/images/short-lived-branch-concept.png)\n\nFor more, see [Short-lived Branches](/branches/short-lived-branches)\n\n### Long-lived\n\nThis corresponds to "Maintenance" Branches that will house several release versions.\nThis kind of branch will:\n\n* last for a long time\n* inevitably diverge more and more from the other branches\n* house several release versions, each of which must pass the quality gate\n  to go to production not be expected to be merged into another branch\n\n![conceptual illustration of long-lived branches.](/images/long-lived-branch-concept.png)\n\nFor more, see [Long-lived Branches](/branches/long-lived-branches)\n\n### Master / Main Branch\n\nThis is the default, and typically corresponds to what\'s being developed for\nyour next release. This is usually known within a development team as\n"master" or "head", and is what is analyzed when no specific branch parameters\nare provided. It is labeled "Main Branch" and defaults to the name "master",\nbut can be renamed from within the interface. When you are not using Developer Edition, this is the only branch you see.\n\n## Analysis\n\nA branch is created when the `sonar.branch.name` parameter is passed during analysis.\n\n| Parameter Name        | Description                                                                                                                                                                                                                                                             |\n| --------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `sonar.branch.name`   | Name of the branch (visible in the UI)                                                                                                                                                                                                                                  |\n| `sonar.branch.target` | Name of the branch where you intend to merge your short-lived branch at the end of its life. If left blank, this defaults to the master branch. It can also be used while initializing a long-lived branch to sync the issues from a branch other than the Main Branch. |\n\n### Git History\n\nBy default, TravisCI only fetches the last 50 git commits. You must use `git fetch --unshallow` to get the full history. If you don\'t, new issues may not be assigned to the correct developer.\n\n### Configuring the Branch type\n\nA regular expression is used to determine whether a branch is treated as long-lived or short-lived. By default, branches that have names starting with either "branch" or "release" will be treated as long-lived.\n\nThis can be updated globally in **Configuration > General > Detection** of long-lived branches or at project\'s level in the **Admininstration > Branches**.\n\nOnce a branch type has been set, it cannot be changed. Explicitly, you cannot transform a long-lived to short-lived branch, or vice-versa.\n\n## See also\n* [Short-lived Branches](short-lived-branches)\n* [Long-lived Branches](long-lived-branches)\n* [Frequently Asked Questions](branches-faq)\n'},{path:"branches/long-lived-branches",content:"---\ntitle: Long-lived Branches\n---\n\n\x3c!-- sonarqube --\x3e\n\n_Branch analysis is available as part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)_\n\n\x3c!-- /sonarqube --\x3e\n\n## Status vs Quality Gate\n\nThe same quality gate that is applied to the project as a whole is automatically applied to long-lived branches as well. This is not editable.\n\n## Issue Creation and Synchronization\n\nDuring the **first analysis only**, issues (type, severity, status, assignee, change log, comments) are synchronized with the Main Branch. In each synchronized issue, a comment is added to the change log of the issue on the long-lived branch: \"The issue has been copied from branch 'master' to branch yyy\".\n\nThen, at each subsequent analysis of the long-lived branch, any new issue that comes from a short-lived branch automatically inherits the attributes (type, severity, ...) the issue had in the short-lived branch. A comment is added to the change log of the issue on the long-lived branch: \"The issue had been copied from branch 'the short-live branch' to branch yyy\".\n\n## Leak Period\n\nBecause long-lived branches will persist for a long time, you are likely to develop and release multiple versions from it, and so you can change the Leak Period of a long-lived branch in **Administration > Branches**.\n\n## Settings and Quality Profiles on Branches\n\nBranch settings and quality profiles default to those set for the master branch, and by design, it's not possible to configure other values.\n"},{path:"branches/short-lived-branches",content:"---\ntitle: Short-lived Branches\n---\n\n\x3c!-- sonarqube --\x3e\n\n_Branch analysis is available as part of [Developer Edition](https://redirect.sonarsource.com/editions/developer.html)_\n\n\x3c!-- /sonarqube --\x3e\n\n## Status vs Quality Gate\n\nFor short-lived branches, there is a kind of hard-coded quality gate focusing only on new issues. Its status is reflected by the green|red signal associated with each short-lived branch:\n\n* status: green / OK or red / ERROR\n* error conditions:\n  * new open bugs > 0\n  * new open vulnerabilities > 0\n  * new open code smells > 0\n\nIt is possible to change the status of a short-lived branch from ERROR to OK (red to green), i.e. mergable, by manually confirming the issues. The same is true for the False-Positive and Won't Fix statuses.\nIt means the status of a short-lived branch will be red only when there are Open issues in the branch.\n\n## Issue Creation and Synchronization\n\nThe issues visible on the short-lived branch are the new issues corresponding to files modified in the branch.\n\nModified files are determined based on the checksum of each file on the sonar.branch.target and the short-lived branch.\n\n## Leak Period\n\nThe ephemeral nature of short-lived branches means no explicit Leak Period is necessary; it's all new code. Thus, no \"new code\" data is available for a short-lived branch.\n\n## Settings and Quality Profiles on Branches\n\nBranch settings and quality profiles default to those set for the master branch, and by design, it's not possible to configure other values.\n\n## Known Limitations\n\n* Only the number of bugs, code smells, vulnerabilities and files are computed. As a consequence, you have no way to get a Quality Gate status as such on short-lived branch.\n* You cannot connect SonarLint to a short-lived branch.\n* Analysis of a short-lived branch based on another short-lived branch is not supported.\n"},{path:"custom-measures",content:'---\ntitle: Custom Measures\nscope: sonarqube\n---\n\nSonarQube collects a maximum of measures in an automated manner but there are some measures for which this is not possible, such as when: the information is not available for collection, the measure is computed by a human, and so on. Whatever the reason, SonarQube provides a service to inject those measures manually and allow you to benefit from other services: the Manual Measures service. The manual measures entered will be picked during the next analysis of the project and thereafter treated as "normal" measures.\n\n## Managing Custom Metrics\nAs with measures that are collected automatically, manual measures are the values collected in each analsis for manual metrics. Therefore, the first thing to do is create the metric you want to save your measure against. In order to do so, log in as a system administrator and go to **[Administration > Configuration > Custom Metrics](/#sonarqube-admin#/admin/custom_metrics)**, where the interface will guide you in creating the Metric you need. \n\n## Managing Custom Measures\nCustom measures can be entered at project level. To add a measure, sign in as a project administrator, navigate to the desired project and choose **Administration > Custom Measures**, where you will find a table with the latest measure value entered for each metric. \n\nValues entered in this interface are "Pending", and will not be visible outside this administrative interface until the next analysis. \n\n'},{path:"fixing-the-water-leak",content:"---\ntitle: Fixing the Water Leak\n---\n\n## What is the Water Leak\n\nImagine you come home one day to find a puddle of water on the kitchen floor. As you watch, the puddle slowly gets larger.\n\nDo you reach for the mop? Or do you try to find the source and fix it? The choice is obvious, right? You find the source of the leak!\n\nSo why do anything different with code quality? When you analyze an application with SonarQube and realize that it has a lot of technical debt, the knee-jerk reaction is generally to start remediating – either that or put together a remediation plan. This is like mopping the floor once a day while ignoring the source of the water.\n\nTypically in this traditional approach, just before release a periodic code quality audit result in findings the developers should act on before releasing. This approach might work in the short term, especially with strong management backing, but it consistently fails in the mid to long run, because:\n\n* The code review comes too late in the process, and no stakeholder is keen to get the problems fixed; everyone wants the new version to ship.\n* Developers typically push back on the recommendations made by an external team that doesn't know the context of the project. And by the way the code under review is obsolete already.\n* There is a clear lack of ownership for code quality with this approach. Who owns quality? No one!\n* What gets reviewed is the entire application before it goes to production and it is obviously not possible to apply the same criteria to all applications. A negotiation will happen for each project, which will drain all credibility from the process\n\nInstead, why not apply the same simple logic you use at home to the way you manage code quality? Fixing the leak means putting the focus on the “new” code, i.e. the code that was added or changed since the last release. Then things get much easier:\n\n* The [Quality Gate](/quality-gates) can be run every day, and passing it is achievable. There are no surprises at release time.\n* It's pretty difficult for developers to push back on problems they introduced the previous day. Instead, they're generally happy to fix the problems while the code is still fresh.\n* There is a clear ownership of code quality\n* The criteria for go/no-go are consistent across applications, and are shared among teams. Indeed new code is new code, regardless of which application it is done in\n* The cost is insignificant because it is part of the development process\n\nAs a bonus, the code that gets changed the most has the highest maintainability, and the code that doesn't get changed has the lowest, which makes a lot of sense. Because of the nature of software, and the fact that we keep making changes to it, the debt will naturally be reduced. Where it isn’t is where it doesn't need to be.\n\n## How to do it\n\nSonarQube offers two main tools to help you find your leaks:\n\n* Leak Period metrics show the variance in your measures between the current code and a specific point you choose in its history, typically the `previous_version`\n* New Code is primarily detected based on SCM \"blame\" data (starting from the first analysis within your Leak Period), with fallback mechanisms when needed. See SCM integration for more details.\n* [Quality Gates](/quality-gates) allow you to set boolean thresholds against which your code is measured. Use them with differential metrics to ensure that your code quality moves in the right direction over time.\n"},{path:"housekeeping",content:"---\ntitle: Housekeeping\n---\n\nWhen you run a new analysis of your project, some data that was previously available is cleaned out of the database. For example the source code of the previous analysis, measures at directory and file levels, and so on are automatically removed at the end of a new analysis. Additionally, some old analysis snapshots are also removed.\n\nWhy? Well, it's useful to analyze a project frequently to see how its quality evolves. It is also useful to be able to see the trends over weeks, months, years. But when you look back in time, you don't really need the same level of detail as you do for the project's current state. To save space and to improve overall performance, the Database Cleaner deletes some rows in the database. Here is its default configuration:\n\n* For each project:\n  * only one snapshot per day is kept after 1 day. Snapshots marked by an event are not deleted.\n  * only one snapshot per week is kept after 1 month. Snapshots marked by an event are not deleted.\n  * only one snapshot per month is kept after 1 year. Snapshots marked by an event are not deleted.\n  * only snapshots with version events are kept after 2 years. Snapshots without events or with only other event types are deleted.\n  * **all snapshots** older than 5 years are deleted, including snapshots marked by an event. \n* All closed issues more than 30 days old are deleted\n* History at package/directory level is removed\n\nThese settings can be changed at [Administration > General > Database Cleaner](/#sonarqube-admin#/admin/settings).\n"},{path:"index",content:"---\ntitle: Documentation\n---\n\x3c!-- sonarqube --\x3e\n[SonarQube](http://www.sonarqube.org/)® software (previously called Sonar) is an open source quality management platform, dedicated to continuously analyze and measure technical quality, from project portfolio to method. If you wish to extend the SonarQube platform with open source plugins, have a look at our [plugin library](https://docs.sonarqube.org/display/PLUG/Plugin+Library).\n\n## I write code\n\n* [Fixing the Water Leak](/fixing-the-water-leak)\n* [Quality Gates](/quality-gates)\n* [Quality Profiles](/quality-profiles)\n\x3c!-- /sonarqube --\x3e\n\n\x3c!-- sonarcloud --\x3e\nSonarCloud is the leading product for Continuous Code Quality online, totally free for open-source projects. It supports all major programming languages, including Java, C#, JavaScript, TypeScript, C/C++ and many more. If your code is closed source, SonarCloud also offers a paid plan to run private analyses.\n\nSonarCloud offers end-to-end integrations for teams leveraging [GitHub](/integrations/github), [VSTS](/integrations/vsts), or [Bitbucket Cloud](/integrations/bitbucketcloud) in their development processes.\n\x3c!-- /sonarcloud --\x3e\n"},{path:"integrations/bitbucketcloud",content:'---\ntitle: Integration with Bitbucket Cloud\nscope: sonarcloud\n---\n\n## Authentication\n\nYou can connect to SonarCloud using your Bitbucket Cloud account. On the [login page](/#sonarcloud#/sessions/new), just click on the "Log in with Bitbucket" button.\n\n## Install SonarCloud add-on for Bitbucket Cloud\n\nOur Bitbucket Cloud application allows users to automate the SonarCloud analysis with Pipelines. It also allows users to view their SonarCloud metrics directly on Bitbucket Cloud via our Code Quality widget and the decoration of pull-requests.\n\nIn Bitbucket Cloud, go to your team\'s "Settings > Find integrations" page, search for "SonarCloud" in the "Code Quality" category and click on "Add" to install the application.\n\n## Analyzing with Pipelines\n\nSonarCloud integrates with Bitbucket Pipelines to make it easier to trigger analyses. Follow the steps:\n\n1.  On SonarCloud, open and follow the "New Project" tutorial available from the `+` icon available at the top right part of the screen. You can copy-paste the command line displayed at the end.\n\n2.  On Bitbucket Cloud, go to the "Settings > Pipelines > Environment variables" page of your team, and add a new SONAR_TOKEN variable that contains the value of the SonarCloud token (something like `9ad01c85336b265406fa6554a9a681a4b281135f`) which you created during the [tutorial](/#sonarcloud#/onboarding) (and which is available inside the command line that you copy-pasted). **Make sure that you click on the "Lock" icon to encrypt and hide this token.**\n\n3.  Inside the `bitbucket-pipelines.yml` file of your repository, copy the command line provided by the tutorial and replace the actual token by its variable name. For example, for a Java Maven-based project, you should have something like:\n\n```\nscript:\n  -mvn sonar:sonar -Dsonar.host.url=https://sonarcloud.io -Dsonar.organization=my-team-org -Dsonar.login=$SONAR_TOKEN\n```\n\nWhen this change on `bitbucket-pipelines.yml` is committed and pushed, Pipelines should automatically run a new build and therefore trigger the analysis of the repository. Shortly after, your project will appear on SonarCloud in your organization.\n\n4.  Once you see your project in SonarCloud, go to the Bitbucket Cloud "Settings > SonarCloud" page of your repository and find it in the select box to link it.\n\nFrom now on, everytime Pipelines triggers a build, SonarCloud will:\n\n* Analyze every new branch that contains the change on the `bitbucket-pipelines.yml` file.\n* Analyze and decorate every pull request based on such a branch.\n\n## Quality widget\n\nSonarCloud provides a widget that shows the current quality metrics of your project directly on the repository\'s Overview page on Bitbucket Cloud.\n\nIf you have configured the analysis with Pipelines as described above, you will see this widget on the "Overview" page of your repository.\n\nIf you haven\'t configured the analysis with Pipelines (maybe because you are using another CI tool), follow these few steps:\n\n1.  Go to the repository where you want to display the widget. On the "Overview" page, you should see an empty SonarCloud widget. Click on the link inside the empty widget or just go directly to your repository\'s "Settings > SonarCloud Settings".\n\n2.  If you\'re not already logged in on SonarCloud, do it by using the options provided there. You can log in with Bitbucket Cloud by clicking on the blue button, or click on "More options" to log in with GitHub or VSTS.\n\n3.  Once you\'re logged in on SonarCloud, you should see a dropdown allowing you to choose one of the projects you administer. Just choose the one you want to link to this Bitbucket repository and click "Save".\n\n4.  You can now go back to your repository\'s Overview page on Bitbucket and see the widget with all current SonarCloud metrics displayed.\n\nIf you want to hide this widget (e.g. because your repository is not analyzed on SonarCloud), you can go to the "Settings > SonarCloud" page of your repository and check "Hide repository overview widget".\n\n## FAQ\n\n**Do you have a sample project on Bitbucket Cloud?**\nFor the time being, you can take a look at this very simple JS project: [Sample project analysed on SonarCloud](https://bitbucket.org/bellingard/fab)\n\n**Pipelines can\'t find sonar-scanner**\nIf you want to analyze a non-Java project (JS, TS, PHP, Python, Go, ...), you will need to download and install the [Scanner CLI](https://redirect.sonarsource.com/doc/install-configure-scanner.html) during the execution of your build prior to the actual code scan. You have two options:\n\n* You can download it (with curl for instance) from the links available on the documentation page and unpack it (preferably in a cached folder for later reuse).\n* On Node environments, you can rely on a [community NPM module](https://www.npmjs.com/package/sonarqube-scanner) to install it globally and therefore make it available in the PATH.\n\n**I don\'t see the any quality information whereas I configured everything**\nMake sure that your browser is not using some extensions like AdBlocks. They tend to break the integration of third-party applications in BitBucket Cloud.\n\n## Upcoming features and improvements\n\nThere are various areas in which you can expect new features and improvements:\n\n* Tighter integration with Pipelines (less parameters to pass on the CLI, availability of the scanner, ...)\n* Pull request decoration with inline comments to show the issues within the PR\n* Better and easier team onboarding\n* Automatic analysis (i.e. no need to configure anything from Pipelines)\n'},{path:"integrations/github",content:'---\ntitle: Integration with GitHub\nscope: sonarcloud\n---\n\n## Authentication\n\nYou can connect to SonarCloud using your GitHub account. On the [login page](/#sonarcloud#/sessions/new), just click on the "Log in with GitHub" button.\n\n## Trigger analyses\n\nSonarCloud currently does not trigger analyses automatically. It\'s up to you to launch them inside your\nexisting CI scripts. Please follow the [tutorial](/#sonarcloud#/onboarding) to get started.\n\n### Using Travis CI?\n\nIf you are using Travis CI, the SonarCloud Travis Add-on will make it easier to activate analyses: \n* Read the [guide to integrate with Travis CI](https://docs.travis-ci.com/user/sonarcloud/)\n* Check out the [various sample projects](https://github.com/SonarSource/sonarcloud_examples) (Java, TypeScript, C/C++, Go, ... etc) that are analyzed on SonarCloud on a frequent basis\n\n## Activating pull request decoration\n\nTo have your pull requests decorated by SonarCloud in GitHub, you need to [install the SonarCloud application](https://github.com/apps/sonarcloud) on your GitHub organization(s).\n\nOnce installed, there is nothing more to do if you are using the Travis Add-on. In any other case, you will need\nto pass the following properties in your script during the analysis:\n\n```\nsonar.pullrequest.base=master\nsonar.pullrequest.branch=feature/my-new-feature\nsonar.pullrequest.key=5\nsonar.pullrequest.provider=GitHub\nsonar.pullrequest.github.repository=my-company/my-repo\n```\n'},{path:"integrations/index",content:"---\ntitle: Integrations\nscope: sonarcloud\n---\n\nSonarCloud integrates with the following cloud services to help developers get the most out of their code:\n\n* [Integration with GitHub](/integrations/github)\n* [Integration with Bitbucket Cloud](/integrations/bitbucketcloud)\n* [Integration with VSTS](/integrations/vsts)\n"},{path:"integrations/vsts",content:'---\ntitle: Integration with VSTS\nscope: sonarcloud\n---\n\n\n## Authentication\n\nYou can connect to SonarCloud using your VSTS account. On the [login page](/#sonarcloud#/sessions/new), just click on the "Log in with VSTS" button.\n\n[[warning]]\n| Only work and school VSTS accounts are authorized to login on SonarCloud.\n\n## Install the SonarCloud VSTS extension\n\nThe SonarCloud VSTS extension brings everything you need to have your projects analyzed on SonarCloud \nvery quickly:\n* Integration with the Build definitions to easily trigger the analysis\n* Pull request decoration to get quick feedback on the code changes\n* Widget to have the overview quality of your projects inside VSTS dashboards\n\nInstall [SonarCloud extension for VSTS](https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarcloud)by clicking on the "Get it free" button.\n\nThen follow the comprehensive [Microsoft lab on how to integrate VSTS with SonarCloud](https://aka.ms/sonarcloudlab).\n\n## Quality Gate Status widget \n\nYou can monitor the Quality Gate status of your projects directly in your VSTS dashboard. Follow these simple steps to configure your widget:\n\n1. Once the VSTS extension is installed and your project has been successfully analyzed, go to one of your VSTS dashboards (or create one). Click on the pen icon in the bottom right corner of the screen, and then on the "+" icon to add a widget. \n\n2. In the list of widgets, select the "Code Quality" one and then click on the "Add" button. An empty widget is added to your dashboard. \n\n3. You can then click on the widget\'s cogwheel icon to configure it.\n\n    * **For public projects:** you can simply select your project from the dropdown. A searchbar inside the dropdown will help you find it easily. Just select it and click on the "Save" button.\n\n    * **For private projects:** you\'ll have to log in using the links provided under the dropdown. Once logged in, your private projects will appear in the dropdown. Select the one you are interested in, and click on "Save".\n'},{path:"keyboard-shortcuts",content:"---\ntitle: Keyboard Shortcuts\norder: 99\n---\n\n## Global\n\n| Shortcut | Action          |\n| -------- | --------------- |\n| `s`      | open search bar |\n| `?`      | open help       |\n\n## Issues Page\n\n| Shortcut         | Action                                        |\n| ---------------- | --------------------------------------------- |\n| `↑` `↓`          | navigate between issues                       |\n| `→`              | go from the list of issues to the source code |\n| `←`              | return back to the list                       |\n| `alt` + `↑` `↓`  | to navigate issue locations                   |\n| `alt` + `←` `→`  | to switch flows                               |\n| `f`              | do an issue transition                        |\n| `a`              | assign issue                                  |\n| `m`              | assign issue to the current user              |\n| `i`              | change severity of issue                      |\n| `c`              | comment issue                                 |\n| `ctrl` + `enter` | submit comment                                |\n| `t`              | change tags of issue                          |\n\n## Measures Page\n\n| Shortcut | Action                                        |\n| -------- | --------------------------------------------- |\n| `↑` `↓`  | select files                                  |\n| `→`      | open file                                     |\n| `←`      | return back to the list                       |\n| `j` `k`  | switch between files                          |\n\n## Rules Page\n\n| Shortcut | Action                                        |\n| -------- | --------------------------------------------- |\n| `↑` `↓`  | navigate between rules                        |\n| `→`      | go from the list of rules to the rule details |\n| `←`      | return back to the list                       |\n"},{path:"look-and-feel",content:'---\ntitle: Look and Feel\nscope: sonarqube\n---\n\n## Home logo\nYou can set your own "home" logo in **[Administration > General > Look & Feel](/#sonarqube-admin#/admin/settings)**. Simply provide an image URL and width. Ideally, the width will scale the height to 30 pixels. This logo will be used in both the menu bar and on the About page.\n\n## Content of the "About" page\nYou also have the ability to add content to the About page, which anonymous users land on by default: **[Administration > General > Look & Feel](/#sonarqube-admin#/admin/settings)**.\n\n## Gravatar\nGravatar support is enabled by default, using gravatar.com. You can configure a different server or disable the feature altogether. When enabled, gravatars show up next to most uses of the user name.\n'},{path:"metric-definitions",content:"---\ntitle: Metric Definitions\n---\n\n## Table of Contents\n\n   \n## Complexity\n**Complexity** (`complexity`)  \nIt is the Cyclomatic Complexity calculated based on the number of paths through the code. Whenever the control flow of a function splits, the complexity counter gets incremented by one. Each function has a minimum complexity of 1. This calculation varies slightly by language because keywords and functionalities do.\n\n[[collapse]]\n| ## Language-specific details\n| Language | Notes\n| ---|---\n| ABAP | The following keywords increase the complexity by one: `AND`, `CATCH`, `CONTINUE`, `DO`, `ELSEIF`, `IF`, `LOOP`, `LOOPAT`, `OR`, `PROVIDE`, `SELECT…ENDSELECT`, `TRY`, `WHEN`, `WHILE`\n| C/C++/Objective-C | The complexity gets incremented by one for: function definitions, `while`, `do while`, `for`, `throw` statements, `switch`, `case`, `default`, `&&` operator, `||` operator, `?` ternary operator, `catch`, `break`, `continue`, `goto`.\n| COBOL | The following commands increase the complexity by one (except when they are used in a copybook): `ALSO`, `ALTER`, `AND`, `DEPENDING`, `END_OF_PAGE`, `ENTRY`, `EOP`, `EXCEPTION`, `EXIT`, `GOBACK`, `CONTINUE`, `IF`, `INVALID`, `OR`, `OVERFLOW`, `SIZE`, `STOP`, `TIMES`, `UNTIL`, `USE`, `VARYING`, `WHEN`, `EXEC CICS HANDLE`, `EXEC CICS LINK`, `EXEC CICS XCTL`, `EXEC CICS RETURN`\n| Java | Keywords incrementing the complexity: `if`, `for`, `while`, `case`, `catch`, `throw`, `&&`, `||`, `?`\n| JavaScript, PHP | Complexity is incremented by one for each: function (i.e non-abstract and non-anonymous constructors, functions, procedures or methods), `if`, short-circuit (AKA lazy) logical conjunction (`&&`), short-circuit (AKA lazy) logical disjunction (`||`), ternary conditional expressions, loop, `case` clause of a `switch` statement, `throw` and `catch` statement, `go to` statement (only for PHP)\n| PL/I | The following keywords increase the complexity by one: `PROC`, `PROCEDURE`, `GOTO`, `GO TO`, `DO`, `IF`, `WHEN`, `|`, `!`, `|=`, `!=`, `&`, `&=`\n| PL/SQL | The complexity gets incremented by one for: the main PL/SQL anonymous block (not inner ones), create procedure, create trigger, procedure_definition, basic loop statement, when_clause_statement (the “when” of simple_case_statement and searched_case_statement), continue_statement, cursor_for_loop_statement, continue_exit_when_clause (The “WHEN” part of the continue and exit statements), exception_handler (every individual “WHEN”), exit_statement, for_loop_statement, forall_statement, if_statement, elsif_clause, raise_statement, return_statement, while_loop_statement, and_expression (“and” reserved word used within PL/SQL expressions), or_expression (“or” reserved word used within PL/SQL expressions), when_clause_expression (the “when” of simple_case_expression and searched_case_expression)\n| VB.NET | The complexity gets incremented by one for: method or constructor declaration (Sub, Function), `AndAlso`, `Case`, `Continue`, `End`, `Error`, `Exit`, `If`, `Loop`, `On Error`, `GoTo`, `OrElse`, `Resume`, `Stop`, `Throw`, `Try`.\n\n**Cognitive Complexity** (`cognitive_complexity`)  \nHow hard it is to understand the code's control flow. See [the Cognitive Complexity White Paper](https://www.sonarsource.com/resources/white-papers/cognitive-complexity.html) for a complete description of the mathematical model applied to compute this measure.\n\n---\n## Duplications\n**Duplicated blocks** (`duplicated_blocks`)  \nNumber of duplicated blocks of lines.\n\n[[collapse]]\n| ## Language-specific details\n| For a block of code to be considered as duplicated:\n|\n| Non-Java projects:  \n| * There should be at least 100 successive and duplicated tokens.\n| * Those tokens should be spread at least on:\n| * 30 lines of code for COBOL\n| * 20 lines of code for ABAP\n| * 10 lines of code for other languages\n|\n|Java projects:  \n| There should be at least 10 successive and duplicated statements whatever the number of tokens and lines. Differences in indentation and in string literals are ignored while detecting duplications.\n \n**Duplicated files** (`duplicated_files`)  \nNumber of files involved in duplications.\n\n**Duplicated lines** (`duplicated_lines`)  \nNumber of lines involved in duplications.\n\n**Duplicated lines (%)** (`duplicated_lines_density`)  \n= `duplicated_lines` / `lines` * 100\n\n---\n## Issues\n**New issues** (`new_violations`)  \nNumber of issues raised for the first time in the New Code period.\n\n**New xxx issues** (`new_xxx_violations`)  \nNumber of issues of the specified severity raised for the first time in the New Code period, where xxx is one of: `blocker`, `critical`, `major`, `minor`, `info`.\n\n**Issues** (`violations`)  \nTotal count of issues in all states.\n\n**xxx issues** (`xxx_issues`)  \nTotal count of issues of the specified severity, where xxx is one of: `blocker`, `critical`, `major`, `minor`, `info`.\n\n**False positive issues** (`false_positive_issues`)  \nTotal count of issues marked False Positive\n\n**Open issues** (`open_issues`)  \nTotal count of issues in the Open state.\n\n**Confirmed issues** (`confirmed_issues`)  \nTotal count of issues in the Confirmed state.\n\n**Reopened issues** (`reopened_issues`)  \nTotal count of issues in the Reopened state\n\n---\n## Maintainability\n**Code Smells** (`code_smells`)   \nTotal count of Code Smell issues.\n\n**New Code Smells** (`new_code_smells`)  \nTotal count of Code Smell issues raised for the first time in the New Code period.\n\n**Maintainability Rating** (`sqale_rating`)  \n(Formerly the SQALE rating.)\nRating given to your project related to the value of your Technical Debt Ratio. The default Maintainability Rating grid is:\n\nA=0-0.05, B=0.06-0.1, C=0.11-0.20, D=0.21-0.5, E=0.51-1\n\nThe Maintainability Rating scale can be alternately stated by saying that if the outstanding remediation cost is:\n\n* <=5% of the time that has already gone into the application, the rating is A\n* between 6 to 10% the rating is a B\n* between 11 to 20% the rating is a C\n* between 21 to 50% the rating is a D\n* anything over 50% is an E\n\n**Technical Debt** (`sqale_index`)  \nEffort to fix all Code Smells. The measure is stored in minutes in the database. An 8-hour day is assumed when values are shown in days.\n\n**Technical Debt on New Code** (`new_technical_debt`)  \nEffort to fix all Code Smells raised for the first time in the New Code period.\n\n**Technical Debt Ratio** (`sqale_debt_ratio`)  \nRatio between the cost to develop the software and the cost to fix it. The Technical Debt Ratio formula is:  \n\t`Remediation cost / Development cost`  \nWhich can be restated as:  \n\t`Remediation cost / (Cost to develop 1 line of code * Number of lines of code)`  \nThe value of the cost to develop a line of code is 0.06 days.\n\n**Technical Debt Ratio on New Code** (`new_sqale_debt_ratio`)  \nRatio between the cost to develop the code changed in the New Code period and the cost of the issues linked to it.\n\n---\n## Quality Gates\n**Quality Gate Status** (`alert_status`)  \nState of the Quality Gate associated to your Project. Possible values are : `ERROR`, `WARN`, `OK`\n\n**Quality Gate Details** (`quality_gate_details`)  \nFor all the conditions of your Quality Gate, you know which condition is failing and which is not.\n\n---\n## Reliability\n**Bugs** (`bugs`)  \nNumber of bug issues.\n\n**New Bugs** (`new_bugs`)  \nNumber of new bug issues.\n\n**Reliability Rating** (`reliability_rating`)  \nA = 0 Bugs  \nB = at least 1 Minor Bug  \nC = at least 1 Major Bug  \nD = at least 1 Critical Bug  \nE = at least 1 Blocker Bug  \n\n**Reliability remediation effort** (`reliability_remediation_effort`)  \nEffort to fix all bug issues. The measure is stored in minutes in the DB. An 8-hour day is assumed when values are shown in days.\n\n**Reliability remediation effort on new code** (`new_reliability_remediation_effort`)  \nSame as _Reliability remediation effort_ but on the code changed in the New Code period.\n\n---\n## Security\n**Vulnerabilities** (`vulnerabilities`)  \nNumber of vulnerability issues.\n\n**New Vulnerabilities** (`new_vulnerabilities`)  \nNumber of new vulnerability issues.\n\n**Security Rating** (`security_rating`)  \nA = 0 Vulnerabilities  \nB = at least 1 Minor Vulnerability  \nC = at least 1 Major Vulnerability  \nD = at least 1 Critical Vulnerability  \nE = at least 1 Blocker Vulnerability  \n\n**Security remediation effort** (`security_remediation_effort`)  \nEffort to fix all vulnerability issues. The measure is stored in minutes in the DB. An 8-hour day is assumed when values are shown in days.\n\n**Security remedation effort on new code** (`new_security_remediation_effort`)  \nSame as _Security remediation effort_ but on the code changed in the New Code period.\n\n---\n## Size\n**Classes** (`classes`)  \nNumber of classes (including nested classes, interfaces, enums and annotations).\n\n**Comment lines** (`comment_lines`)  \nNumber of lines containing either comment or commented-out code.\n\nNon-significant comment lines (empty comment lines, comment lines containing only special characters, etc.) do not increase the number of comment lines.\n\nThe following piece of code contains 9 comment lines:\n```\n/**                                    +0 => empty comment line\n *                                     +0 => empty comment line\n * This is my documentation            +1 => significant comment\n * although I don't                    +1 => significant comment\n * have much                           +1 => significant comment\n * to say                              +1 => significant comment\n *                                     +0 => empty comment line\n ***************************           +0 => non-significant comment\n *                                     +0 => empty comment line\n * blabla...                           +1 => significant comment\n */                                    +0 => empty comment line\n  \n/**                                    +0 => empty comment line\n * public String foo() {               +1 => commented-out code\n *   System.out.println(message);      +1 => commented-out code\n *   return message;                   +1 => commented-out code\n * }                                   +1 => commented-out code\n */                                    +0 => empty comment line\n ```\n[[collapse]]\n| ## Language-specific details\n| Language | Note\n| ---|---\n| COBOL | Lines containing the following instructions are counted both as comments and lines of code: `AUTHOR`, `INSTALLATION`, `DATE-COMPILED`, `DATE-WRITTEN`, `SECURITY`.\n| Java | File headers are not counted as comment lines (becuase they usually define the license).\n\n**Comments (%)** (`comment_lines_density`)  \nDensity of comment lines = Comment lines / (Lines of code + Comment lines) * 100\n\nWith such a formula:\n* 50% means that the number of lines of code equals the number of comment lines  \n* 100% means that the file only contains comment lines  \n\n**Directories** (`directories`)  \nNumber of directories.\n\n**Files** (`files`)  \nNumber of files.\n\n**Lines** (`lines`)  \nNumber of physical lines (number of carriage returns).\n\n**Lines of code** (`ncloc`)  \nNumber of physical lines that contain at least one character which is neither a whitespace nor a tabulation nor part of a comment.\n[[collapse]]\n| ## Language-specific details\n| Language | Note\n| --- | ---\n| COBOL | Generated lines of code and pre-processing instructions (`SKIP1`, `SKIP2`, `SKIP3`, `COPY`, `EJECT`, `REPLACE`) are not counted as lines of code.\n\n**Lines of code per language** (`ncloc_language_distribution`)  \nNon Commenting Lines of Code Distributed By Language\n\n**Functions** (`functions`)  \nNumber of functions. Depending on the language, a function is either a function or a method or a paragraph.\n[[collapse]]\n| ## Language-specific details\n| Language | Note\n| ---|---\n| COBOL | It is the number of paragraphs.\n| Java | Methods in anonymous classes are ignored.\n| VB.NET | Accesors are not considered to be methods.\n\n**Projects** (`projects`)  \nNumber of projects in a Portfolio.\n\n**Statements** (`statements`)  \nNumber of statements.\n\n---\n## Tests\n**Condition coverage** (`branch_coverage`)  \nOn each line of code containing some boolean expressions, the condition coverage simply answers the following question: 'Has each boolean expression been evaluated both to true and false?'. This is the density of possible conditions in flow control structures that have been followed during unit tests execution.\n\n`Condition coverage = (CT + CF) / (2*B)`   \nwhere  \n* CT = conditions that have been evaluated to 'true' at least once\n* CF = conditions that have been evaluated to 'false' at least once\n* B = total number of conditions\n\n**Condition coverage on new code** (`new_branch_coverage`)  \nIdentical to Condition coverage but restricted to new / updated source code.\n\n**Condition coverage hits** (`branch_coverage_hits_data`)  \nList of covered conditions.\n\n**Conditions by line** (`conditions_by_line`)  \nNumber of conditions by line.\n\n**Covered conditions by line** (`covered_conditions_by_line`)  \nNumber of covered conditions by line.\n\n**Coverage** (`coverage`)  \nIt is a mix of Line coverage and Condition coverage. Its goal is to provide an even more accurate answer to the following question: How much of the source code has been covered by the unit tests?\n\n`Coverage = (CT + CF + LC)/(2*B + EL)`  \nwhere  \n* CT = conditions that have been evaluated to 'true' at least once\n* CF = conditions that have been evaluated to 'false' at least once\n* LC = covered lines = lines_to_cover - uncovered_lines\n* B = total number of conditions\n* EL = total number of executable lines (`lines_to_cover`)\n\n**Coverage on new code** (`new_coverage`)  \nIdentical to Coverage but restricted to new / updated source code.\n\n**Line coverage (`line_coverage`)  \nOn a given line of code, Line coverage simply answers the following question: Has this line of code been executed during the execution of the unit tests?. It is the density of covered lines by unit tests:\n\n`Line coverage = LC / EL`  \nwhere\n* LC = covered lines (`lines_to_cover` - `uncovered_lines`)\n* EL = total number of executable lines (`lines_to_cover`)\n\n**Line coverage on new code** (`new_line_coverage`)  \nIdentical to Line coverage but restricted to new / updated source code.\n\n**Line coverage hits** (`coverage_line_hits_data`)  \nList of covered lines.\n\n**Lines to cover** (`lines_to_cover`)  \nNumber of lines of code which could be covered by unit tests (for example, blank lines or full comments lines are not considered as lines to cover).\n\n**Lines to cover on new code** (`new_lines_to_cover`)  \nIdentical to Lines to cover but restricted to new / updated source code.\n\n**Skipped unit tests** (`skipped_tests`)  \nNumber of skipped unit tests.\n\n**Uncovered conditions** (`uncovered_conditions`)  \nNumber of conditions which are not covered by unit tests.\n\n**Uncovered conditions on new code** (`new_uncovered_conditions`)  \nIdentical to Uncovered conditions but restricted to new / updated source code.\n\n**Uncovered lines** (`uncovered_lines`)  \nNumber of lines of code which are not covered by unit tests.\n\n**Uncovered lines on new code** (`new_uncovered_lines`)  \nIdentical to Uncovered lines but restricted to new / updated source code.\n\n**Unit tests** (`tests`)  \nNumber of unit tests.\n\n**Unit tests duration** (`test_execution_time`)  \nTime required to execute all the unit tests.\n\n**Unit test errors** (`test_errors`)  \nNumber of unit tests that have failed.\n\n**Unit test failures** (`test_failures`)  \nNumber of unit tests that have failed with an unexpected exception.\n\n**Unit test success density (%)** (`test_success_density`)  \n`Test success density = (Unit tests - (Unit test errors + Unit test failures)) / Unit tests * 100`\n"},{path:"organizations/index",content:'---\ntitle: Organizations\nscope: sonarcloud\n---\n\n## Overview\n\nAn organization is a space where a team or a whole company can collaborate across many projects.\n\nAn organization consists of:\n* Projects, on which users collaborate\n* [Members](/organizations/manage-team), who can have different persmissions on the projects\n* [Quality Profiles](/quality-profiles) and [Quality Gates](/quality-gates), which can be customized and shared accross projects\n\nThere are 2 kind of organizations:\n* **Personal organizations**. Each account has a personal organization linked to it. This is typically where open-source developers host their personal projects. It is not possible to delete this kind of organization.\n* **Standard organization**. This is the kind of organization that users want to create for their companies or for their open-source communities. As soon as you want to collaborate, it is a good idea to create such an organization.\n\nOrganizations can be on:\n* **Free plan**. This is the default plan. Every project in an organization on the free plan is public.\n* **Paid plan**. This plan unlocks the ability to have private projects. Go to the "Billing" page of your organization to upgrade it to the paid plan.\n\nDepending on which plan the organization is in, its [visibility](/organizations/organization-visibility) will change.\n'},{path:"organizations/manage-team",content:'---\ntitle: Manage a Team\nscope: sonarcloud\n---\n\nMembers can collaborate on the projects in the organizations to which they belong. Depending on their permisssions within the organization, members can:\n* Analyse projects\n* Manage project settings (permissions, visibility, quality profiles, ...)\n* Update issues\n* Manage quality gates and quality profiles\n* Administer the organization itself\n\n## Adding Members\n\nAdding members is done on the "Members" page of the organization, and this can be done only by an administrator of \nthe organization.\n\nAdding a user as a member is possible only if that user has already signed up on SonarCloud. If the user never authenticated to\nthe system, the administrator will simply not be able to find the user in the search modal window.\n\n## Granting permissions\n\nOnce added, a user can be granted permissions to perform various operations in the organization. It is up to the \nadministrator who added the user to make sure that she gets the relevant permissions.\n\nOrganization admins will prefer to create groups to manage permissions, and add new users to those\ngroups through the "Members" page. With such an approach, they won\'t have to manage individal permissions at\nproject level for instance.\n\n## Future evolutions\n\nFuture versions of SonarCloud will make this onboarding process easier thanks to better integrations with GitHub, \nBitbucket Cloud and VSTS: users won\'t have to sign up prior to joining an organization, and their permissions will \nbe retrieved at best from the ones existing on the other systems.\n'},{path:"organizations/organization-visibility",content:'---\ntitle: Organization Visibility\nscope: sonarcloud\n---\n\n## Free plan organization\n\nFree plan organizations are public. This means that almost everything is visible to any user - even anonymous ones:\n\n* Projects\n* Issues\n* Quality Profiles\n* Quality Gates\n* Rules\n\nThe following pages are restricted:\n\n* Members: to members of the organization\n* Administration pages: to administrators of the organization\n\n## Paid plan organization\n\nPaid plan organizations are private. This means that nothing is visible to non-members of the organization. In other words, you need to be a member of the organization to see:\n\n* Projects - which are private by default\n* Issues\n* Quality Profiles\n* Quality Gates\n* Rules\n* Members\n\nThe administration pages are obviously also restricted to administrators of the organization.\n\n### Want to make one project public?\n\nIf you are on a paid plan organization but want to make a project public (for instance because you are developing an open-source library), this is possible. You will have to manually make the project public in its "Administration > Permissions" page. Once done, you will notice the "Public" badge on the project.\n\nAs soon as you have one public project, the following pages will become visible to any user:\n\n* Projects\n* Issues\n* Rules\n\n"Quality Profiles" and "Quality Gates" pages will remain restricted to members only - since you might not want to unveil some information used by your private projects.\n'},{path:"privacy",content:"---\ntitle: Privacy\nscope: sonarcloud\n---\n\nThe privacy policy specifies how data collected on this website is used. Thank you for visiting our website and your interest in our services and products. As the protection of your personal data is an important concern for us, we will explain below what information we collect during your visit to our website, as they are processed and whether or how these may be used.\n\n## PERSONAL DATA\n\nPersonal information is information about personal or material circumstances of an identified or identifiable natural person. This includes information such as your first and last name, your postal or residential address, telephone numbers and date of birth. Information that can not be directly related to your real identity – such as your favorite websites or the number of users of a page – are not considered as personal data.\n\n## COLLECTION AND PROCESSING OF PERSONAL DATA\n\nAs the operator and creator of the website, we do not store personal data itself automatically. If you go to our website, the provider – where the web server is hosted – may temporarily store data for the purpose of system security such as the connection of the computer, the web pages you visit, the date and duration of the visit, data about the used browser software and operating system and the web page from which you visit us. In addition to that, personal information such as your name, address, phone number or e-mail will only be stored, if you have provided this information voluntarily, eg. as part of a registration, a survey, a contest, to carry out an order or contract or an information request.\n\n## USE AND DISCLOSURE OF PERSONAL DATA\n\nPersonal data you provided may be used solely for the purpose of technical website administration and to fulfill your wishes and requirements, thus primarily to processing the order with you or to respond to your request. Only if you have previously given your consent or – if stipulated by legal regulations – you entered no objection, we use this data for product surveys and marketing purposes. We don’t share, sell or transfer your personal data to third parties, unless this is necessary for the purpose of the contract or unless you have explicitly consented. For example it may be necessary, that in case of an product order we share your address and order with our suppliers.\n\n## USE OF WEB ANALYSIS SOFTWARE\n\nTo improve the structure and the data we offer on our website, we might use open source or proprietary web analysis software. Our evaluations will be based on summary or averaged information amalgamated for the large numbers of people visiting the vebsite. The data provided by won’t be matched with any individual’s data from other sources.\n\nData collected might include IP, time and duration of the visit, what pages are visited, used browser and add-ons/plugins, search-engines and referrer. While statistic tools might use a “cookie” to distinguish between individual visitors, the collected data doesn’t allow to identify individuals.\n\n## SECURITY\n\nWe take all the necessary technical and organisational security measures to protect your personal data from loss and misuse. Your data is stored in a secure operating environment that is not accessible to the public. If you communicate with us via e-mail, please note that the confidentiality of the information is not guaranteed. The contents of e-mails can be intercepted by third parties. In case of doubt we therefore recommend to send confidential information only by snail mail.\n\n## RIGHT OF ACCESS TO PERSONAL DATA\n\nUpon written request you will be informed by us what information we stored about you (such as name or address).\n\n## CONTACT\n\nIf you have questions regarding the processing of personal data or in case of requests for information, suggestions or complaints, please [contact us](/#sonarcloud#/about/contact) directly.\n"},{path:"quality-gates",content:"---\ntitle: Quality Gates\n---\n\n## Overview\n\nA quality gate is the best way to enforce a quality policy in your organization.\nIt's there to answer ONE question: can I deliver my project to production today or not?\n\nIn order to answer this question, you define a set of Boolean conditions based on measure thresholds against which projects are measured. For example:\n\n* No new blocker issues\n* Code coverage on new code greater than 80%\n* Etc.\n\nIdeally, all projects will be verified against the same quality gate, but that's not always practical. For instance, you may find that:\n\n* Technological implementation differs from one application to another (you might not require the same code coverage on new code for Web or Java applications).\n* You want to ensure stronger requirements on some of your applications (internal frameworks for example).\n* Etc.\n\nWhich is why you can define as many quality gates as you wish. Quality Gates are defined and managed in the **[Quality Gates](/#sonarqube#/quality_gates)** page found in the top menu.\n\n## Use the Best Quality Gate Configuration\n\nThe quality gate \"Sonar way\" is provided by SonarSource, activated by default and considered as built-in and so read-only. It represents our view of the best way to implement the Fixing the Water Leak concept. At each SonarQube release, we adjust automatically this default quality gate according to SonarQube's capabilities.\n\nThree metrics allow you to enforce a given Rating of Reliability, Security and Maintainability, not just overall but also on new code. These metrics are recommended and come as part of the default quality gate. We strongly advise you to adjust your own quality gates to use them to make feedback more clear to your developers looking at their quality gate on their project page.\n\nDon't forget also that quality gate conditions must use differential values. There is no point for example to check an absolute value such as : Number of Lines of Code is greater than 1000.\n\n### Recommended Quality Gate\n\nThe `Sonar way` Built-in quality gate is recommended for most projects. If focuses on keeping new code clean, rather than spending a lot of effort remediating old code. Out of the box, it's already set as the default profile.\n\n## Quality Gate Status\n\nThe current status is displayed prominently at the top of the Project Page:\n\n![Quality Gate Status](/images/quality-gate-status.jpeg)\n\n## Getting Notified When a Quality Gate Fails\n\nThanks to the notification mechanism, users can be notified when a quality gate fails. To do so, subscribe to the **New quality gate status** notification either for all projects or a set of projects you're interested in.\n\n## Security\n\nQuality Gates can be accessed by any user (even anonymous users). All users can view every aspect of a quality gate.\n\nTo make changes (create, edit or delete) users must be granted the **Administer Quality Profiles and Gates** permission.\n\nA **project administrator** can choose which quality gates his/her project is associated with. See Project Settings for more.\n\n## Defining Quality Gates\n\nTo manage quality gates, go to **[Quality Gates](/#sonarqube#/quality_gates)** (top menu bar).\n\nEach Quality Gate condition is a combination of:\n\n* measure\n* period: **Value** (to date) or **Leak** (differential value over the Leak period)\n* comparison operator\n* warning value (optional)\n* error value (optional)\n\nFor instance, a condition might be:\n\n* measure: Blocker issue\n* period: Value\n* comparison operator: >\n* error value: 0\n\nWhich can be stated as: No blocker issues.\n"},{path:"quality-profiles",content:"---\ntitle: Quality Profiles\n---\n\n## Overview\n\nThe Quality Profiles service is central to SonarQube, since it is where you define your requirements by defining sets of **rules** (ex: Methods should not have a Cognitive Complexity greater than 15).\n\nIdeally, all projects will be measured with the same profile for any given language, but that's not always practical. For instance, you may find that:\n\n* The technological implementation differs from one application to another (for example, different coding rules may apply when building threaded or non-threaded Java applications).\n* You want to ensure stronger requirements on some of your applications (internal frameworks for example).\n* Etc.\n\nWhich is why you can define as many quality profiles as you wish even though it is recommended to have as few Quality Profiles as possible to ensure consistency across the projects in your company. To manage quality profiles, go to \x3c!-- sonarqube --\x3e[**Quality Profiles**](/#sonarqube#/profiles)\x3c!-- /sonarqube --\x3e\x3c!-- sonarcloud --\x3e**Quality Profiles** page of your organization\x3c!-- /sonarcloud --\x3e, where you'll find profiles grouped by language.\n\nEach language plugin comes with a predefined, built-in profile (usually called \"Sonar way\") so that you can get started very quickly with SonarQube analyses. This is why as soon as you install a new language plugin, at least one quality profile will be available for you. Each language must have a default profile (marked with the Default tag). Projects that are not explicitly associated with a specific profile will be analyzed using the language's default profile.\n\nWhen starting from a new installation, it's tempting to use Sonar way as your default profile because it contains all the rules that are generally applicable to most projects. But as a best practice, you should create a new profile (you can populate it by copying the contents of Sonar way) and use it instead. Why? First because Sonar way profiles aren't editable, so you won't be able to customize it to your needs. Also, that lets you treat Sonar way as a baseline against which you can track your own profile as you make changes to it (and you will). Plus, Sonar way is typically updated with each new version of the plugin to add rules and sometimes adjust rule severities. Any profile that inherits from the built-in Sonar Way will de-facto be automatically updated at the same time.\n\n## How do I...\n\n### Delegate the management of Quality Profiles to someone else?\n\nBy default, only users with the \"Administer Quality Profiles\" permission can edit Quality Profiles. But in large organizations, it may not be desirable to grant permissions to change all the Quality Profiles without distinction. That's why you can also grant users/groups the permission to edit an individual Quality Profile so that, for instance, the management of the Swift profile can be delegated to a group of Swift experts, and the same for COBOL, ...\n\nThis delegation of permission can only be performed by someone who already has the \"Administer Quality Profiles\" permission or individual edit rights on the profile to which additional permissions should be granted. The interface to grant individual permissions is available on the profile detail page.\n\n### Copy the rules from one profile to another?\n\nMany times people want to work from a profile that's based on a built-in profile without actually using the built-in profile. The easiest thing to do in this case is to go to the original profile, we'll call it _Source_, in **Quality Profiles**. From there, click through on the total number of rules in _Source_ to land on the **Rules** page at a pre-narrowed search of _Source_'s rules. Use **Bulk Activate** to turn Source's rules on in your target profile.\n\n### Know what's changed in a profile?\n\nWhen SonarQube notices that an analysis was performed with a profile that is different in some way from the previous analysis, a Quality Profile event is added to the project's event log. To see the changes in a profile, navigate to the profile (**Quality Profiles > [ Profile Name ]**), and choose **Changelog**. This may help you understand how profile changes impact the issues raised in an analysis.\n\nAdditionally, users with Quality Profile administration privileges are notified by email each time a built-in profile (one that is provided directly by an analyzer) is updated. These updates can only be caused by analyzer updates.\n\n### Copy a profile from one SonarQube instance to another?\n\nUse the **Back up** feature on the source instance to export the profile to an XML file. Use the **Restore Profile** feature on the target instance to import the file. Note that some [limitations](https://jira.sonarsource.com/browse/SONAR-5366) on this feature exist.\n\n![Restore Quality Profile](/images/restore-quality-profile.jpeg)\n\n### Apply a core set of rules plus additional rules to a project?\n\nLet's say your company has a minimum set of coding rules that all teams must follow, but you want to add rules that are specific to the in use technology in your project. Those rules are good for your team, but irrelevant or even misleading for others. This situation calls for inheritance. Set up a base profile, we'll call it _Root_ with your core set of rules. Then create a child profile, we'll call it _Sprout_. Once it's created, you can **Change parent** to inherit from _Root_, then add your missing rules.\n\n### Make sure my non-default profile is used on a project?\n\nOne profile for each language is marked the default. Barring any other intervention, all projects that use that language will be analyzed with that profile. To have a project analyzed by a non-default profile instead, start from **Quality Profiles**, and click through on your target profile, then use the Projects part of the interface to manage which projects are explicitly assigned to the profile.\n\n### Make sure I've got all the relevant new rules in my profile?\n\nEach time a language plugin update is released, new rules are added, but they won't appear automatically in your profile unless you're using a built-in profile such as _Sonar way_.\n\nIf you're not using a built-in profile, you can compare your profile to the built-in profile to see what new on-by-default rules you're missing.\n\nAnother option is to go to the **Rules** space, and use the **Available Since** search facet to see what rules have been added to the platform since the day you upgraded the relevant plugin.\n\nAnd finally, the profile interface itself will help you be aware of rules added in a new plugin version in the **Latest New Rules** section on the right of the interface.\n\n### Compare two profiles?\n\nStarting from the **Quality Profiles** page, click through on one of the profiles you'd like to compare, then use the **Actions > Compare** interface to select the second profile and see the differences.\n\n### Make sure I don't have any deprecated rules in my profile?\n\nThe **Deprecated Rules** section of the rules interface itself is your first warning that a profile contains deprecated rules. This pink-background section gives the total number of instances of deprecated rules that are currently active in profiles, and a breakdown of deprecated count per profile. A click-through here takes you to the **Rules** page to edit the profile in question.\n\nAlternately, you can perform a **Rules** search for the rules in a profile (either manually or by clicking-through from **Quality Profiles** page) and use the **Status** rule search facet to narrow the list to the ones that need attention.\n\n## Security\n\nThe Quality Profiles service can be accessed by any user (even anonymous users). All users can view every aspect of a profile. That means anyone can see which rules are included in a profile, and which ones have been left out, see how a profile has changed over time, and compare the rules in any two profiles.\n\nTo make rule profile changes (create, edit or delete) users must be granted the **Administer Quality Profiles and Gates** permission.\n\nA **project administrator** can choose which profiles his project is associated with. See Project Settings for more.\n"},{path:"security-reports",content:"---\ntitle: Security Reports\n---\n\n## What do the Security Reports show?\nThe Security Reports are designed to quickly give you the big picture on your application's security, with breakdowns of just where you stand in regard to each of the [OWASP Top 10](https://www.owasp.org/index.php/Top_10-2017_Top_10), and [SANS Top 25](https://www.sans.org/top25-software-errors) categories, and [CWE](http://cwe.mitre.org/)-specific details.\nThe Security Reports are fed by the analyzers, which rely on the rules activated in your quality profiles to raise security issues. If there are no rules corresponding to a given OWASP category activated in your Quality Profile, you will get no issues linked to that specific category and the rating displayed will be A. That won't mean you are safe for that category, but that you need to activate more rules (assuming some exist).\n\n## What's the difference between a Hotspot and a Vulnerability?\nVulnerabilities are points in the code which are open to attack.\nSecurity Hotspots are security-sensitive pieces of code that should be carefully reviewed by someone with a security auditor hat. This person can be:\n* a member of the development team who is more sensitive to security problems \n* someone outside the development team contracted for the purpose of reviewing these Hotspots.\n\nThe main goal of Security Hotspots is to help focus the efforts of the security auditors who manually review application source code. The second goal is to educate developers and to increase their security-awareness. \nHaving a Hotspot in your application does not mean there is a problem. What it does mean is that a human, preferably a security auditor/expert should look over the code to see if the sensitive piece of code is being used in the safest manner.\n\n## Why don't I see any Hotspots?\nThey are three reasons you might not see any Hotspots:\n* it is possible you really have none of them because the code has been written without using any security-sensitive API. \n* it is possible that Hotspot rules are available, but not yet activated in your Quality Profile, and so naturally no issues are raised\n* it is more likely that the analyzer for the langauge you're using does not yet offer Hotspot rules, and so it doesn't raise any Hotspots regardless of the quality of how many are actually there, but this last option will disappear over time.\n\n## Why don't I see any Vulnerabilities?\nYou might not see any Vulnerabilities for more or less the same reasons as for Hotspots, but it may be more surprising for Vulnerabilities because you may see some Vulnerabilities reported in the Project homepage, while there are none in the Security Reports. This is because the language analyzer may not yet provide the \"Security Standards\" metadata required for issues to be visible on the Security Reports. This metadata is basically the link between a Rule (and its issues) and the \"OWASP Top 10\" or \"SANS Top 25\" categories. Without this link, there is no way to associate an already existing Vulnerability to the Security Standard categories and so to display security issues correctly in the reports. Every analyzer version released by SonarSource after July 2018 should feed the \"Security Standards\" and be compatible with the Hotspot issue type. \n\n## I'm a developer. Should I care about Hotspots?\nProbably not. Hotspots, as such, aren't really actionable. They simply mark *potential* problems, so there's really nothing to do immediately on the code. That's why you don't receive notifications when Hotspot issues are raised, and why Hotspots aren't shown in the Issues page by default.\n\n## What if my Hotspot really marks a Vulnerability?\nIf you look at the code where a Hotspot is raised and realize that there really is a problem, click on the current status (probably `Open`) to register that you've *Detect*ed a Vulnerability at that point in the code. Once you do, it will be converted to a Vulnerability, and the developer who last touched the line will receive \"new issue\" notifications (if she's signed up to get them).\n\n## What happens after my Hotspot becomes a Vulnerability?\nOnce you've *Detect*ed that there really is a problem at a Hotspot location, it will be assigned to the appropriate developer, who will make a fix, and must then `Request Review` *via the UI*. That request moves the issue from Vulnerability back to Hotspot. From there, it's up to the security auditor to either `Accept` or `Reject` the fix. Accepting the fix will mark it `Won't Fix`, and rejecting it will turn it back into a Vulnerability, putting it back in the developer's queue.\n\n## What does it mean for a Hotspot to be marked \"Won't Fix\"?\nThe `Won't Fix` designation is used to indicate that a Hotspot has been reviewed and there is no way, as of now, to exploit this piece of code to create an attack.\n\n\n"},{path:"security",content:"---\ntitle: SonarCloud Security\nscope: sonarcloud\n---\n\nWe know that your code is very important to you and your business. We also know that no one wants proven bugs or vulnerabilities found on their source code to be unveiled to third-parties. This is why we take security extremely seriously.\n\n## Hosting\n\nSonarCloud is hosted on Amazon AWS in Frankfurt. \n\n## System security\n\nWe keep system up to date, OS packages are updated at least weekly. SonarCloud is on its own AWS VPC. We have firewall at VPC and VM level.\n\nExcept the Operations team, no SonarSource employee has access to the system, especially the database which stores source code and analysis results.\n\nThe Operations team has access to the system through secured channels (SSH) only. \n\n## Data security\n\nAll the data is stored on a Postgres RDS instance which only the Operation has access to.\n\nIsolation of data per organization is ensured at software level, which secures access to source code to organization members only.\n\nThe source code is not encrypted in the database, but the access to the database is restricted to SonarSource operations team and can be done only through a SSH tunnel.\n\nThe DB is backed up everyday by Amazon RDS mechanism, with 7 days retention.\n\n## Software security\n\nThe Web Application and Web APIs regularly pass penetration testing conducted by a an external company, specialized in cyber and application security, certified in accordance to ISO-27001 and which is also member of the OWASP.\n\n## Communications\n\nAll communications are done over TLS 1.2:\n* Navigating in the Web application\n* Using WS APIs\n* Running analysis (by the scanners) from CI services and pushing analysis reports to SonarCloud\n\n## Authentication\n\nPrimary authentication on the system is available only through OAuth authentication with GitHub, Bitbucket Cloud and Microsoft VSTS. As a consequence, users don’t have a password on SonarCloud, and are as protected as what they expect (especially with 2FA activated on those systems). \n \nFor WS API calls or source code analysis triggered from CI services, only revocable user tokens are accepted.\n\n## Payment\n\nWhen you subscribe to the paid plan on SonarCloud, your credit card information never transit through our system nor it gets stored on the server. It's handed off to [Braintree Payment Solutions](https://www.braintreepayments.com), a company dedicated to storing your sensitive data on [PCI-Compliant](http://en.wikipedia.org/wiki/Payment_Card_Industry_Data_Security_Standard) servers.\n"},{path:"sonarcloud-pricing",content:"---\ntitle: Pricing\nscope: sonarcloud\n---\n\nSubscribing to a paid plan on SonarCloud allows you to analyze unlimited private projects. You can make your code visible by members of your organization only.\n\n## How is SonarCloud priced?\n\nSonarCloud is priced on a monthly basis per lines of code. You pay up front for a maximum number of lines of code to be analyzed in your organization.\n\nFind your max LOC below to see what it will cost you per month:\n\n| Up to lines of code  | Price per month in € |\n| ------------- |--------------:|\n| 100k          | 10            |\n| 250k          | 75            | \n| 500k          | 150           |\n| 1M            | 250           |\n| 2M            | 500           |\n| 5M            | 1'500         |\n| 10M           | 3'000         |\n| 20M           | 4'000         |\n\n\n## What's the difference between the free and paid plans?\n\n2 options are available to start using SonarCloud: free and paid plans. Both plans let you benefit from all the features available on SonarCloud.\n\n*Free plan:*\n\n* For open source projects\n* Anyone can see your projects\n* You choose who can edit your projects\n* Unlimited lines of code (LOCs)\n\n*Paid plan:*\n\n* If you need (some or all) private projects\n* You choose who can see your private projects\n* You choose who can edit your projects\n* Priced by lines of private code\n\n## How do I activate the paid plan?\n\nYou can activate the paid plan on the \"Administration > Billing\" page of your organization. \n\n## What payment options are available?\n\nPayment is done online by credit card and will happen automatically every month, based on the plan you choose. \n\nWe also accept to receive a purchase order and a wire transfer payment, if ordering a yearly subscription for more than 1M LOCs. In this case, you need to contact us through the Contact form.\n\n## Can I try a private project on SonarCloud for free?\n\nYour first 14 days are on us. You just have to upgrade your organization to a paid plan, and fill your credit card information to get started. After your trial, if you love it you can continue using SonarCloud and you will be charged for the plan you selected when you first started your free trial. You can cancel anytime.\n\n## What is a Line of Code (LOC) on SonarCloud?\n\nLOCs are computed by summing up the LOCs of each project analyzed in SonarCloud. The LOCs used for a project are the LOCs found during the most recent analysis of this project.\n\n\n## How are Lines of Code (LOCs) counted towards billing?\n\nOnly LOC from your private projects are counted toward your maximum number of LOCs. If your project contains branches, the counted LOCs are the ones of the biggest branch.\n\nThe count is not related to how frequently the source code is analyzed. If your private project has a 6K LOCs and you analyze it 100 times in the month, this will be counted as 6K for the billing.\n\nIf you are getting close to the threshold you will be notified to either upgrade your plan or reduce the number of LOCs in your projects.\n\n## When will I be invoiced?\n\nYou will be invoiced once a month, the day of the month after your trial ends. For example if you start your free trial on January 1st, it will last till January 14th and you will be first billed on January 15th for your upcoming month, aka January 15th to February 15th.\n\n## How do I get invoices?\n\nYou can download PDF invoices for every payment from the \"Administration > Billing\" page of your organization.\n\nIf you want to get those invoices by email, please [contact us](/#sonarcloud#/about/contact).\n\n## Can I stop using the service?\n\nYes, you can stop using SonarCloud anytime you want. You simply need to downgrade your organization to the free plan.\n\n## Still have more questions?\n\nContact us [here](https://about.sonarcloud.io/contact).\n\n\n"},{path:"webhooks",content:'---\ntitle: Webhooks\n---\n\nWebhooks notify external services when a project analysis is complete. An HTTP POST request including a JSON payload is sent to each URL. URLs may be specified at both the project and global levels. Project-level specification does not replace global-level webhooks. All hooks at both levels are called.\nPlugins\n\nThe HTTP(S) call:\n\n* is made regardless of the status of the Background Task\n* includes a JSON document as payload, using the POST method\n* has a content type of "application/json", with UTF-8 encoding\n\n## Configuration\n\nYou can configure up to 10 webhooks in in **Administration > Webhooks**.\n\nAn additional set of 10 webhooks can be configured at the global level in **Administration > Configuration > Webhooks**.\n\nIf configured, all 20 will be executed.\n\n## Delivery and Payload\n\n### Delivery\n\nThe Webhook administration console shows the result and timestamp of the most recent delivery of each webhook with the payload available via the list icon. Results and payloads of earlier deliveries are available from the tools menu to the right of each webhook\n\nResponse records are purged after 30 days.\n\nThe URL must respond within 10 seconds or the delivery is marked as failed.\n\n### Payload\n\nAn HTTP header "X-SonarQube-Project" with the project key is sent to allow quick identification of the project involved\n\nThe Payload is a JSON document which includes:\n\n* when the analysis was performed: see "analysedAt"\n* the identification of the project analyzed: see "project"\n* each Quality Gate criterion checked and its status: see "qualityGate"\n* the Quality Gate status of the project: see "qualityGate.status"\n* the status and the identifier of the Background Task : see "status" and "taskId"\n* user-specified properties: see "properties"\n\n#### Example\n\n```\n{\n    "analysedAt": "2016-11-18T10:46:28+0100",\n    "project": {\n        "key": "org.sonarqube:example",\n        "name": "Example"\n    },\n    "properties": {\n    },\n    "qualityGate": {\n        "conditions": [\n            {\n                "errorThreshold": "1",\n                "metric": "new_security_rating",\n                "onLeakPeriod": true,\n                "operator": "GREATER_THAN",\n                "status": "OK",\n                "value": "1"\n            },\n            {\n                "errorThreshold": "1",\n                "metric": "new_reliability_rating",\n                "onLeakPeriod": true,\n                "operator": "GREATER_THAN",\n                "status": "OK",\n                "value": "1"\n            },\n            {\n                "errorThreshold": "1",\n                "metric": "new_maintainability_rating",\n                "onLeakPeriod": true,\n                "operator": "GREATER_THAN",\n                "status": "OK",\n                "value": "1"\n            },\n            {\n                "errorThreshold": "80",\n                "metric": "new_coverage",\n                "onLeakPeriod": true,\n                "operator": "LESS_THAN",\n                "status": "NO_VALUE"\n            }\n        ],\n        "name": "SonarQube way",\n        "status": "OK"\n    },\n    "serverUrl": "http://localhost:9000",\n    "status": "SUCCESS",\n    "taskId": "AVh21JS2JepAEhwQ-b3u"\n}\n```\n\n## Additional parameters\n\nA basic authentication mechanism is supported by providing user/password in the URL of the Webhook such as `https://myLogin:myPassword@my_server/foo`.\n\nIf you provide additional properties to your SonarQube Scanner using the pattern `sonar.analysis.*`, these properties will be automatically added to the section "properties" of the payload.\n\nFor example these additional parameters:\n\n```\nsonar-scanner -Dsonar.analysis.scmRevision=628f5175ada0d685fd7164baa7c6382c1f25cab4 -Dsonar.analysis.buildNumber=12345\n```\n\nWould add this to the payload:\n\n```\n"properties": {\n  "sonar.analysis.scmRevision": "628f5175ada0d685fd7164baa7c6382c1f25cab4",\n  "sonar.analysis.buildNumber": "12345"\n}\n```\n'}]},1563:function(e,n,t){"use strict";t.r(n);var o=t(534),a=t(557),i=t.n(a),s=t(541),r=t(551),l=t.n(r),c=t(535);function u(e){return e.endsWith("index")?e.split("/").slice(0,-1).join("/"):e}var d=6;function h(e){for(var n=0,t=0;t<e.length;t++)if(/\s/.test(e[t])&&n++,n===d)return t<e.length-1?e.substring(0,t)+"...":e;return e}function p(e){var n=[],t=0,o=e.findIndex(function(e){return e.marked});if(o>0){var a=function(e){for(var n=0,t=e.length-1;t>=0;t--)if(/\s/.test(e[t])&&n++,n===d)return t>0?"..."+e.substring(t+1):e;return e}(e[o-1].text);n.push({text:a,marked:!1}),t+=a.length}n.push(e[o]),t+=e[o].text.length;for(var i=o+1;i<e.length;i++){if(t+e[i].text.length>100){a=h(e[i].text);return n.push({text:a,marked:!1}),n}n.push(e[i]),t+=e[i].text.length}return n}function m(e,n){for(var t=[],o=0,a=0,i=0,s=l()(n.map(function(e){return{pos:e.from,start:!0}}).concat(n.map(function(e){return{pos:e.to,start:!1}})),function(e){return e.pos},function(e){return Number(!e.start)});i<s.length;i++){var r=s[i];r.start?(0===a&&o!==r.pos&&(t.push({text:e.substring(o,r.pos),marked:!1}),o=r.pos),a++):0===--a&&o!==r.pos&&(t.push({text:e.substring(o,r.pos),marked:!0}),o=r.pos)}return o<e.length-1&&t.push({text:e.substr(o),marked:!1}),t}var y,f=t(659),g=(y=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,n){e.__proto__=n}||function(e,n){for(var t in n)n.hasOwnProperty(t)&&(e[t]=n[t])},function(e,n){function t(){this.constructor=e}y(e,n),e.prototype=null===n?Object.create(n):(t.prototype=n.prototype,new t)}),b=Object.assign||function(e){for(var n,t=1,o=arguments.length;t<o;t++)for(var a in n=arguments[t])Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a]);return e},v=function(e){function n(){var n=null!==e&&e.apply(this,arguments)||this;return n.getMenuEntriesHierarchy=function(e){var t=function(e,n){return e.filter(function(e){var t=e.relativeName.split("/"),o=n?n.split("/").length:0;return(!n||0===e.relativeName.indexOf(n))&&(t.length===o+1&&"index"!==t[o]||"index"===t[o+1])})}(n.props.pages,e);return l()(t.map(function(e){var t=u(e.relativeName),o=""!==t?n.getMenuEntriesHierarchy(t):[];return b({},e,{children:o})}),function(e){return e.order})},n.renderEntry=function(e,t){var a=e.relativeName===n.props.splat,i=function(e,n){return 0===e.indexOf(u(n.relativeName))}(n.props.splat||"",e),r=10+25*t,l=e.children,d=void 0===l?[]:l;return o.createElement(o.Fragment,{key:e.relativeName},o.createElement(s.Link,{className:c("list-group-item",{active:a}),style:{paddingLeft:r},to:"/documentation/"+e.relativeName},o.createElement("h3",{className:"list-group-item-heading"},d.length>0&&o.createElement(f.a,{className:"little-spacer-right",open:i}),e.title)),i&&d.map(function(e){return n.renderEntry(e,t+1)}))},n}return g(n,e),n.prototype.render=function(){var e=this;return o.createElement(o.Fragment,null,this.getMenuEntriesHierarchy().map(function(n){return e.renderEntry(n,0)}))},n}(o.PureComponent),w=t(1260),S=t.n(w);function k(e){var n=e.active,t=e.result;return o.createElement(s.Link,{className:c("list-group-item",{active:n}),to:"/documentation/"+t.page.relativeName},o.createElement(C,{result:t}),o.createElement(x,{result:t}))}function C(e){var n,t=e.result,a=t.highlights.title;if(a&&a.length>0){var i=m(t.page.title,a.map(function(e){return{from:e[0],to:e[0]+e[1]}}));n=o.createElement(T,{tokens:i})}else n=t.page.title;return o.createElement("h3",{className:"list-group-item-heading",style:{fontWeight:"normal"}},n)}function x(e){var n=e.result,t=n.highlights.text;if(t&&t.length>0){var a=m(n.page.text,t.map(function(e){return{from:e[0],to:e[0]+e[1]}}));return o.createElement("div",{className:"note"},o.createElement(T,{tokens:p(a)}))}return null}function T(e){var n=e.tokens;return o.createElement(o.Fragment,null,n.map(function(e,n){return o.createElement(o.Fragment,{key:n},e.marked?o.createElement("mark",{key:n},e.text):e.text)}))}var A=function(){var e=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,n){e.__proto__=n}||function(e,n){for(var t in n)n.hasOwnProperty(t)&&(e[t]=n[t])};return function(n,t){function o(){this.constructor=n}e(n,t),n.prototype=null===t?Object.create(t):(o.prototype=t.prototype,new o)}}(),P=function(e){function n(n){var t=e.call(this,n)||this;return t.index=S()(function(){var e=this;this.ref("relativeName"),this.field("title",{boost:10}),this.field("text"),this.metadataWhitelist=["position"],n.pages.forEach(function(n){return e.add(n)})}),t}return A(n,e),n.prototype.render=function(){var e=this,n=this.props.query,t=this.index.search(n+"~1 "+n+"*").map(function(n){var t=e.props.pages.find(function(e){return e.relativeName===n.ref}),o={};return Object.keys(n.matchData.metadata).forEach(function(e){Object.keys(n.matchData.metadata[e]).forEach(function(t){var a=n.matchData.metadata[e][t].position;o[t]=(o[t]||[]).concat(a)})}),{page:t,highlights:o}}).filter(function(e){return e.page});return o.createElement(o.Fragment,null,t.map(function(n){return o.createElement(k,{active:n.page.relativeName===e.props.splat,key:n.page.relativeName,result:n})}))},n}(o.PureComponent),_=t(584),I=function(){var e=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,n){e.__proto__=n}||function(e,n){for(var t in n)n.hasOwnProperty(t)&&(e[t]=n[t])};return function(n,t){function o(){this.constructor=n}e(n,t),n.prototype=null===t?Object.create(t):(o.prototype=t.prototype,new o)}}(),O=function(e){function n(){var n=null!==e&&e.apply(this,arguments)||this;return n.state={query:""},n.handleSearch=function(e){n.setState({query:e})},n}return I(n,e),n.prototype.render=function(){return o.createElement(o.Fragment,null,o.createElement(_.a,{className:"big-spacer-top spacer-bottom",minLength:2,onChange:this.handleSearch,placeholder:"Search for pages or keywords",value:this.state.query}),o.createElement("div",{className:"documentation-results panel"},o.createElement("div",{className:"list-group"},this.state.query?o.createElement(P,{pages:this.props.pages,query:this.state.query,splat:this.props.splat}):o.createElement(v,{pages:this.props.pages,splat:this.props.splat}))))},n}(o.PureComponent),E=t(1030),j=t.n(E),N=t(716),q=t.n(N),L=t(1153),R=t(1008),B=t(64);function Q(){return L.map(function(e){var n=Object(R.separateFrontMatter)(e.content),t=function(e){var n=j()().parse(e),t=[];return q()(n,function(e){"text"!==e.type&&"inlineCode"!==e.type||t.push(e.value)}),t.join(" ").replace(/\s+/g," ")}(Object(R.filterContent)(n.content));return{relativeName:e.path,title:n.frontmatter.title,order:Number(n.frontmatter.order||-1),scope:n.frontmatter.scope?n.frontmatter.scope.toLowerCase():void 0,text:t,content:e.content}}).filter(function(e){return"static"!==e.scope&&(Object(B.isSonarCloud)()||"sonarcloud"!==e.scope)})}var z=t(19),W=t(651),F=t(18),G=t(7),D=(t(1099),function(){var e=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,n){e.__proto__=n}||function(e,n){for(var t in n)n.hasOwnProperty(t)&&(e[t]=n[t])};return function(n,t){function o(){this.constructor=n}e(n,t),n.prototype=null===t?Object.create(t):(o.prototype=t.prototype,new o)}}()),H=function(e){function n(){var n=null!==e&&e.apply(this,arguments)||this;return n.mounted=!1,n.pages=Q(),n}return D(n,e),n.prototype.componentDidMount=function(){var e=document.getElementById("footer");e&&e.classList.add("page-footer-with-sidebar","documentation-footer")},n.prototype.componentWillUnmount=function(){var e=document.getElementById("footer");e&&e.classList.remove("page-footer-with-sidebar","documentation-footer")},n.prototype.render=function(){var e=this,n=this.props.params.splat,t=void 0===n?"index":n,a=this.pages.find(function(e){return e.relativeName===t}),r=Object(G.l)("documentation.page");if(!a)return o.createElement(o.Fragment,null,o.createElement(i.a,{title:r},o.createElement("meta",{content:"noindex nofollow",name:"robots"})),o.createElement(z.default,{withContainer:!1}));var l="index"===t;return o.createElement("div",{className:"layout-page"},o.createElement(i.a,{title:l?r:a.title+" - "+r},!Object(B.isSonarCloud)()&&o.createElement("meta",{content:"noindex nofollow",name:"robots"})),o.createElement(W.a,{className:"layout-page-side-outer"},function(n){var a=n.top;return o.createElement("div",{className:"layout-page-side",style:{top:a}},o.createElement("div",{className:"layout-page-side-inner"},o.createElement("div",{className:"layout-page-filters"},o.createElement("div",{className:"documentation-page-header"},o.createElement(s.Link,{to:"/documentation/"},o.createElement("h1",null,Object(G.l)("documentation.page")))),o.createElement(O,{pages:e.pages,splat:t}))))}),o.createElement("div",{className:"layout-page-main"},o.createElement("div",{className:"layout-page-main-inner"},o.createElement("div",{className:"boxed-group"},o.createElement(F.default,{className:"documentation-content cut-margins boxed-group-inner",content:a.content,displayH1:!0})))))},n}(o.PureComponent);n.default=H},19:function(e,n,t){"use strict";t.r(n),t.d(n,"default",function(){return l});var o=t(534),a=t(557),i=t(541),s=t(20),r=t(7);function l(e){var n=e.withContainer,t=void 0===n||n?s.default:o.Fragment;return o.createElement(t,null,o.createElement(a.Helmet,{defaultTitle:Object(r.l)("404_not_found"),defer:!1}),o.createElement("div",{className:"page-wrapper-simple",id:"bd"},o.createElement("div",{className:"page-simple",id:"nonav"},o.createElement("h2",{className:"big-spacer-bottom"},Object(r.l)("page_not_found")),o.createElement("p",{className:"spacer-bottom"},Object(r.l)("address_mistyped_or_page_moved")),o.createElement("p",null,o.createElement(i.Link,{to:"/"},Object(r.l)("go_back_to_homepage"))))))}},20:function(e,n,t){"use strict";t.r(n),t.d(n,"default",function(){return r});var o=t(534),a=t(715),i=t(542),s=t(724);function r(e){var n=e.children;return o.createElement("div",{className:"global-container"},o.createElement("div",{className:"page-wrapper",id:"container"},o.createElement(s.a,{className:"navbar-global",height:i.globalNavHeightRaw}),n),o.createElement(a.a,null))}},651:function(e,n,t){"use strict";var o,a=t(591),i=t.n(a),s=t(534),r=(o=Object.setPrototypeOf||{__proto__:[]}instanceof Array&&function(e,n){e.__proto__=n}||function(e,n){for(var t in n)n.hasOwnProperty(t)&&(e[t]=n[t])},function(e,n){function t(){this.constructor=e}o(e,n),e.prototype=null===n?Object.create(n):(t.prototype=n.prototype,new t)}),l=function(e){function n(n){var t=e.call(this,n)||this;return t.getPosition=function(){var e=t.container&&t.container.getBoundingClientRect();return e?{top:window.pageYOffset+e.top,left:window.pageXOffset+e.left}:{top:0,left:0}},t.debouncedOnResize=i()(function(){return t.forceUpdate()},250),t}return r(n,e),n.prototype.componentDidMount=function(){this.forceUpdate(),window.addEventListener("resize",this.debouncedOnResize)},n.prototype.componentWillUnmount=function(){window.removeEventListener("resize",this.debouncedOnResize)},n.prototype.render=function(){var e=this;return s.createElement("div",{className:this.props.className,ref:function(n){return e.container=n}},this.props.children(this.getPosition()))},n}(s.PureComponent);n.a=l}}]);
//# sourceMappingURL=282.2395c4c2.chunk.js.map